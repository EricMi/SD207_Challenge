{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge SD207 - 2017\n",
    "*<p>Author: Pengfei MI, Rui SONG</p>*\n",
    "*<p>Date: 06/06/2017</p>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import mode\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "from presets import Preset\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define some usefull functions\n",
    "def load_sound_files(file_paths):\n",
    "    raw_sounds = []\n",
    "    for fp in file_paths:\n",
    "        X,sr = librosa.load(fp)\n",
    "        raw_sounds.append(X)\n",
    "    return raw_sounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['audio/b010_0_30.wav' 'audio/b010_60_90.wav' 'audio/b010_150_180.wav'\n",
      " 'audio/b010_30_60.wav' 'audio/b010_120_150.wav' 'audio/b022_120_150.wav'\n",
      " 'audio/b022_60_90.wav' 'audio/b022_180_210.wav' 'audio/b022_30_60.wav'\n",
      " 'audio/b022_90_120.wav' 'audio/b022_150_180.wav' 'audio/b022_0_30.wav'\n",
      " 'audio/b011_180_210.wav' 'audio/b011_90_120.wav' 'audio/b011_150_180.wav'\n",
      " 'audio/b011_60_90.wav' 'audio/b011_120_150.wav' 'audio/b011_30_60.wav'\n",
      " 'audio/b011_0_30.wav' 'audio/a112_90_120.wav' 'audio/a112_120_150.wav'\n",
      " 'audio/a112_30_60.wav' 'audio/a112_60_90.wav' 'audio/a112_0_30.wav'\n",
      " 'audio/b107_0_30.wav' 'audio/b107_30_60.wav' 'audio/b107_90_120.wav'\n",
      " 'audio/b107_60_90.wav' 'audio/b110_210_240.wav' 'audio/b110_120_150.wav'\n",
      " 'audio/b110_180_210.wav' 'audio/b110_150_180.wav' 'audio/b110_270_300.wav'\n",
      " 'audio/b110_90_120.wav' 'audio/b110_30_60.wav' 'audio/b110_0_30.wav'\n",
      " 'audio/b110_240_270.wav' 'audio/b110_60_90.wav' 'audio/a083_30_60.wav'\n",
      " 'audio/a083_0_30.wav' 'audio/a083_150_180.wav' 'audio/a083_60_90.wav'\n",
      " 'audio/a083_120_150.wav' 'audio/a083_90_120.wav' 'audio/a060_60_90.wav'\n",
      " 'audio/a060_0_30.wav' 'audio/a060_120_150.wav' 'audio/a060_90_120.wav'\n",
      " 'audio/a060_30_60.wav' 'audio/b050_0_30.wav' 'audio/b050_120_150.wav'\n",
      " 'audio/b050_90_120.wav' 'audio/b050_150_180.wav' 'audio/b050_30_60.wav'\n",
      " 'audio/b050_60_90.wav' 'audio/b050_180_210.wav' 'audio/b096_90_120.wav'\n",
      " 'audio/b096_240_270.wav' 'audio/b096_180_210.wav' 'audio/b096_210_240.wav'\n",
      " 'audio/b096_0_30.wav' 'audio/b096_270_300.wav' 'audio/b096_150_180.wav'\n",
      " 'audio/b096_30_60.wav' 'audio/b096_120_150.wav' 'audio/a133_120_150.wav'\n",
      " 'audio/a133_180_210.wav' 'audio/a133_150_180.wav' 'audio/a133_0_30.wav'\n",
      " 'audio/a133_30_60.wav' 'audio/a133_60_90.wav' 'audio/a095_60_90.wav'\n",
      " 'audio/a095_30_60.wav' 'audio/a095_150_180.wav' 'audio/a095_90_120.wav'\n",
      " 'audio/a095_120_150.wav' 'audio/b099_180_210.wav' 'audio/b099_210_240.wav'\n",
      " 'audio/b099_60_90.wav' 'audio/b099_30_60.wav' 'audio/b099_90_120.wav'\n",
      " 'audio/b094_90_120.wav' 'audio/b094_210_240.wav' 'audio/b094_30_60.wav'\n",
      " 'audio/b094_150_180.wav' 'audio/b094_120_150.wav' 'audio/b094_0_30.wav'\n",
      " 'audio/a131_30_60.wav' 'audio/a131_210_240.wav' 'audio/a131_0_30.wav'\n",
      " 'audio/a131_60_90.wav' 'audio/a131_150_180.wav' 'audio/a131_90_120.wav'\n",
      " 'audio/a131_120_150.wav' 'audio/a040_60_90.wav' 'audio/a040_90_120.wav'\n",
      " 'audio/a040_30_60.wav' 'audio/a040_141_171.wav' 'audio/a040_0_30.wav'\n",
      " 'audio/a096_180_210.wav' 'audio/a096_0_30.wav' 'audio/a096_90_120.wav'\n",
      " 'audio/a096_30_60.wav' 'audio/a096_210_240.wav' 'audio/a096_120_150.wav'\n",
      " 'audio/a096_60_90.wav' 'audio/a096_270_300.wav' 'audio/a096_150_180.wav'\n",
      " 'audio/a096_240_270.wav' 'audio/a059_30_60.wav' 'audio/a059_150_180.wav'\n",
      " 'audio/a059_0_30.wav' 'audio/a059_90_120.wav' 'audio/a059_120_150.wav'\n",
      " 'audio/a059_60_90.wav' 'audio/b085_90_120.wav' 'audio/b085_120_150.wav'\n",
      " 'audio/b085_60_90.wav' 'audio/b085_0_30.wav' 'audio/b085_180_210.wav'\n",
      " 'audio/b085_150_180.wav' 'audio/b087_60_90.wav' 'audio/b087_30_60.wav'\n",
      " 'audio/b087_150_180.wav' 'audio/b087_0_30.wav' 'audio/b087_90_120.wav'\n",
      " 'audio/b087_120_150.wav' 'audio/a113_245_275.wav' 'audio/a113_30_60.wav'\n",
      " 'audio/a113_215_245.wav' 'audio/a113_90_120.wav' 'audio/a113_60_90.wav'\n",
      " 'audio/a113_155_185.wav' 'audio/a113_185_215.wav' 'audio/a031_0_30.wav'\n",
      " 'audio/a031_30_60.wav' 'audio/a031_90_120.wav' 'audio/a031_150_180.wav'\n",
      " 'audio/a031_60_90.wav' 'audio/a031_120_150.wav' 'audio/b032_60_90.wav'\n",
      " 'audio/b032_180_210.wav' 'audio/b032_210_240.wav' 'audio/b032_90_120.wav'\n",
      " 'audio/b032_150_180.wav' 'audio/b032_270_300.wav' 'audio/b032_30_60.wav'\n",
      " 'audio/b032_0_30.wav' 'audio/b032_240_270.wav' 'audio/b033_120_150.wav'\n",
      " 'audio/b033_180_210.wav' 'audio/b033_210_240.wav' 'audio/b033_90_120.wav'\n",
      " 'audio/b033_0_30.wav' 'audio/b033_60_90.wav' 'audio/b033_30_60.wav'\n",
      " 'audio/b034_0_30.wav' 'audio/b034_180_210.wav' 'audio/b034_120_150.wav'\n",
      " 'audio/b034_150_180.wav' 'audio/b034_210_240.wav' 'audio/b034_60_90.wav'\n",
      " 'audio/b034_30_60.wav' 'audio/b034_90_120.wav' 'audio/b025_150_180.wav'\n",
      " 'audio/b025_90_120.wav' 'audio/b025_180_210.wav' 'audio/b025_60_90.wav'\n",
      " 'audio/b025_0_30.wav' 'audio/b025_120_150.wav' 'audio/b038_150_180.wav'\n",
      " 'audio/b038_90_120.wav' 'audio/b038_210_240.wav' 'audio/b038_120_150.wav'\n",
      " 'audio/b038_0_30.wav' 'audio/b038_30_60.wav' 'audio/b038_60_90.wav'\n",
      " 'audio/b071_30_60.wav' 'audio/b071_120_150.wav' 'audio/b071_150_180.wav'\n",
      " 'audio/b071_60_90.wav' 'audio/b071_90_120.wav' 'audio/a084_242_272.wav'\n",
      " 'audio/a084_92_122.wav' 'audio/a084_62_92.wav' 'audio/a084_122_152.wav'\n",
      " 'audio/a084_212_242.wav' 'audio/a084_152_182.wav' 'audio/a084_182_212.wav'\n",
      " 'audio/a156_210_240.wav' 'audio/a156_60_90.wav' 'audio/a156_240_270.wav'\n",
      " 'audio/a156_120_150.wav' 'audio/a156_0_30.wav' 'audio/a156_90_120.wav'\n",
      " 'audio/a156_270_300.wav' 'audio/a099_240_270.wav' 'audio/a099_180_210.wav'\n",
      " 'audio/a099_60_90.wav' 'audio/a099_150_180.wav' 'audio/a099_210_240.wav'\n",
      " 'audio/a099_0_30.wav' 'audio/a099_120_150.wav' 'audio/b115_120_150.wav'\n",
      " 'audio/b115_60_90.wav' 'audio/b115_240_270.wav' 'audio/b115_210_240.wav'\n",
      " 'audio/b115_0_30.wav' 'audio/b115_180_210.wav' 'audio/b115_30_60.wav'\n",
      " 'audio/a120_240_270.wav' 'audio/a120_210_240.wav' 'audio/a120_120_150.wav'\n",
      " 'audio/a120_0_30.wav' 'audio/a120_150_180.wav' 'audio/a018_90_120.wav'\n",
      " 'audio/a018_30_60.wav' 'audio/a018_0_30.wav' 'audio/a018_180_210.wav'\n",
      " 'audio/a018_150_180.wav' 'audio/a018_120_150.wav' 'audio/a018_60_90.wav'\n",
      " 'audio/a017_120_150.wav' 'audio/a017_60_90.wav' 'audio/a017_0_30.wav'\n",
      " 'audio/a017_150_180.wav' 'audio/a017_30_60.wav' 'audio/a017_90_120.wav'\n",
      " 'audio/a017_180_210.wav' 'audio/b014_0_30.wav' 'audio/b014_120_150.wav'\n",
      " 'audio/b014_30_60.wav' 'audio/b014_150_180.wav' 'audio/b014_60_90.wav'\n",
      " 'audio/b014_90_120.wav' 'audio/b008_120_150.wav' 'audio/b008_90_120.wav'\n",
      " 'audio/b008_0_30.wav' 'audio/b008_180_210.wav' 'audio/b008_60_90.wav'\n",
      " 'audio/b008_150_180.wav' 'audio/a001_150_180.wav' 'audio/a001_0_30.wav'\n",
      " 'audio/a001_60_90.wav' 'audio/a001_90_120.wav' 'audio/a001_30_60.wav'\n",
      " 'audio/a001_120_150.wav' 'audio/b006_150_180.wav' 'audio/b006_90_120.wav'\n",
      " 'audio/b006_30_60.wav' 'audio/b006_180_210.wav' 'audio/b006_0_30.wav'\n",
      " 'audio/b006_60_90.wav' 'audio/b006_120_150.wav' 'audio/b065_144_174.wav'\n",
      " 'audio/b065_0_30.wav' 'audio/b065_84_114.wav' 'audio/b065_174_204.wav'\n",
      " 'audio/b065_54_84.wav' 'audio/b065_204_234.wav' 'audio/b065_114_144.wav'\n",
      " 'audio/a145_180_210.wav' 'audio/a145_60_90.wav' 'audio/a145_150_180.wav'\n",
      " 'audio/a145_120_150.wav' 'audio/a145_210_240.wav' 'audio/a145_90_120.wav'\n",
      " 'audio/a145_240_270.wav' 'audio/a145_30_60.wav' 'audio/b061_0_30.wav'\n",
      " 'audio/b061_60_90.wav' 'audio/b061_30_60.wav' 'audio/a148_120_150.wav'\n",
      " 'audio/a148_270_300.wav' 'audio/a148_60_90.wav' 'audio/a148_180_210.wav'\n",
      " 'audio/a148_240_270.wav' 'audio/b082_90_120.wav' 'audio/b082_0_30.wav'\n",
      " 'audio/b082_120_150.wav' 'audio/b082_60_90.wav' 'audio/b082_150_180.wav'\n",
      " 'audio/a076_60_90.wav' 'audio/a076_270_300.wav' 'audio/a076_180_210.wav'\n",
      " 'audio/a076_90_120.wav' 'audio/a076_240_270.wav' 'audio/a076_120_150.wav'\n",
      " 'audio/a076_210_240.wav' 'audio/a076_30_60.wav' 'audio/a016_120_150.wav'\n",
      " 'audio/a016_0_30.wav' 'audio/a016_180_210.wav' 'audio/a016_150_180.wav'\n",
      " 'audio/a016_90_120.wav' 'audio/a016_60_90.wav' 'audio/a016_30_60.wav'\n",
      " 'audio/a006_30_60.wav' 'audio/a006_150_180.wav' 'audio/a006_90_120.wav'\n",
      " 'audio/a006_60_90.wav' 'audio/a006_0_30.wav' 'audio/a023_30_60.wav'\n",
      " 'audio/a023_150_180.wav' 'audio/a023_180_210.wav' 'audio/a023_0_30.wav'\n",
      " 'audio/a023_60_90.wav' 'audio/a023_90_120.wav' 'audio/a023_120_150.wav'\n",
      " 'audio/b112_203_233.wav' 'audio/b112_113_143.wav' 'audio/b112_30_60.wav'\n",
      " 'audio/b112_60_90.wav' 'audio/b112_173_203.wav' 'audio/b112_143_173.wav'\n",
      " 'audio/b112_0_30.wav' 'audio/b109_90_120.wav' 'audio/b109_30_60.wav'\n",
      " 'audio/b109_0_30.wav' 'audio/b109_60_90.wav' 'audio/b109_180_210.wav'\n",
      " 'audio/b109_210_240.wav' 'audio/b109_240_270.wav' 'audio/b109_120_150.wav'\n",
      " 'audio/b109_150_180.wav' 'audio/b108_90_120.wav' 'audio/b108_0_30.wav'\n",
      " 'audio/b108_60_90.wav' 'audio/b108_30_60.wav' 'audio/a130_90_120.wav'\n",
      " 'audio/a130_60_90.wav' 'audio/a130_150_180.wav' 'audio/a130_180_210.wav'\n",
      " 'audio/a130_210_240.wav' 'audio/a130_0_30.wav' 'audio/a130_120_150.wav'\n",
      " 'audio/a130_30_60.wav' 'audio/a109_210_240.wav' 'audio/a109_0_30.wav'\n",
      " 'audio/a109_150_180.wav' 'audio/a109_90_120.wav' 'audio/a109_60_90.wav'\n",
      " 'audio/a109_120_150.wav' 'audio/a109_180_210.wav' 'audio/a082_30_60.wav'\n",
      " 'audio/a082_150_180.wav' 'audio/a082_90_120.wav' 'audio/a082_60_90.wav'\n",
      " 'audio/a082_120_150.wav' 'audio/a101_30_60.wav' 'audio/a101_150_180.wav'\n",
      " 'audio/a101_90_120.wav' 'audio/a101_180_210.wav' 'audio/a101_0_30.wav'\n",
      " 'audio/a137_60_90.wav' 'audio/a137_90_120.wav' 'audio/a137_0_30.wav'\n",
      " 'audio/a137_150_180.wav' 'audio/a137_240_270.wav' 'audio/a137_270_300.wav'\n",
      " 'audio/a137_180_210.wav' 'audio/a137_30_60.wav' 'audio/a137_210_240.wav'\n",
      " 'audio/b045_30_60.wav' 'audio/b045_180_210.wav' 'audio/b045_0_30.wav'\n",
      " 'audio/b045_120_150.wav' 'audio/b045_90_120.wav' 'audio/b045_60_90.wav'\n",
      " 'audio/a128_131_161.wav' 'audio/a128_101_131.wav' 'audio/a128_41_71.wav'\n",
      " 'audio/a128_11_41.wav' 'audio/a128_161_191.wav' 'audio/a128_191_221.wav'\n",
      " 'audio/a128_71_101.wav' 'audio/b098_0_30.wav' 'audio/b098_30_60.wav'\n",
      " 'audio/b098_120_150.wav' 'audio/b098_180_210.wav' 'audio/b098_60_90.wav'\n",
      " 'audio/b098_150_180.wav' 'audio/b098_210_240.wav' 'audio/b098_90_120.wav'\n",
      " 'audio/b093_180_210.wav' 'audio/b093_30_60.wav' 'audio/b093_120_150.wav'\n",
      " 'audio/b093_90_120.wav' 'audio/b093_60_90.wav' 'audio/b093_0_30.wav'\n",
      " 'audio/b093_150_180.wav' 'audio/a057_150_180.wav' 'audio/a057_30_60.wav'\n",
      " 'audio/a057_120_150.wav' 'audio/a057_60_90.wav' 'audio/a057_0_30.wav'\n",
      " 'audio/a057_90_120.wav' 'audio/a098_30_60.wav' 'audio/a098_150_180.wav'\n",
      " 'audio/a098_90_120.wav' 'audio/a098_240_270.wav' 'audio/a098_210_240.wav'\n",
      " 'audio/a098_270_300.wav' 'audio/a098_180_210.wav' 'audio/a098_0_30.wav'\n",
      " 'audio/a098_120_150.wav' 'audio/a098_60_90.wav' 'audio/a069_30_60.wav'\n",
      " 'audio/a069_60_90.wav' 'audio/a069_120_150.wav' 'audio/a069_90_120.wav'\n",
      " 'audio/a069_0_30.wav' 'audio/a105_270_300.wav' 'audio/a105_210_240.wav'\n",
      " 'audio/a105_90_120.wav' 'audio/a105_30_60.wav' 'audio/a105_150_180.wav'\n",
      " 'audio/a105_0_30.wav' 'audio/a105_180_210.wav' 'audio/a105_120_150.wav'\n",
      " 'audio/b103_120_150.wav' 'audio/b103_0_30.wav' 'audio/b103_90_120.wav'\n",
      " 'audio/b103_60_90.wav' 'audio/b103_30_60.wav' 'audio/b106_30_60.wav'\n",
      " 'audio/b106_0_30.wav' 'audio/b106_90_120.wav' 'audio/b106_120_150.wav'\n",
      " 'audio/b106_150_180.wav' 'audio/b106_60_90.wav' 'audio/b030_90_120.wav'\n",
      " 'audio/b030_0_30.wav' 'audio/b030_270_300.wav' 'audio/b030_30_60.wav'\n",
      " 'audio/b030_210_240.wav' 'audio/b030_150_180.wav' 'audio/b030_240_270.wav'\n",
      " 'audio/b030_120_150.wav' 'audio/b030_180_210.wav' 'audio/b030_60_90.wav'\n",
      " 'audio/b031_60_90.wav' 'audio/b031_210_240.wav' 'audio/b031_180_210.wav'\n",
      " 'audio/b031_30_60.wav' 'audio/b031_0_30.wav' 'audio/b031_120_150.wav'\n",
      " 'audio/b031_90_120.wav' 'audio/b031_150_180.wav' 'audio/b036_60_90.wav'\n",
      " 'audio/b036_210_240.wav' 'audio/b036_0_30.wav' 'audio/b036_90_120.wav'\n",
      " 'audio/b036_180_210.wav' 'audio/b036_150_180.wav' 'audio/b039_120_150.wav'\n",
      " 'audio/b039_150_180.wav' 'audio/b039_60_90.wav' 'audio/b039_90_120.wav'\n",
      " 'audio/b039_180_210.wav' 'audio/b039_0_30.wav' 'audio/b039_30_60.wav'\n",
      " 'audio/b039_210_240.wav' 'audio/b047_90_120.wav' 'audio/b047_60_90.wav'\n",
      " 'audio/b047_30_60.wav' 'audio/b047_0_30.wav' 'audio/b047_120_150.wav'\n",
      " 'audio/a158_60_90.wav' 'audio/a158_0_30.wav' 'audio/a158_30_60.wav'\n",
      " 'audio/b075_120_150.wav' 'audio/b075_0_30.wav' 'audio/b075_60_90.wav'\n",
      " 'audio/b075_150_180.wav' 'audio/b075_90_120.wav' 'audio/b075_30_60.wav'\n",
      " 'audio/a155_270_300.wav' 'audio/a155_150_180.wav' 'audio/a155_210_240.wav'\n",
      " 'audio/a155_240_270.wav' 'audio/a155_180_210.wav' 'audio/a155_60_90.wav'\n",
      " 'audio/a155_120_150.wav' 'audio/a155_30_60.wav' 'audio/a155_0_30.wav'\n",
      " 'audio/a155_90_120.wav' 'audio/b116_180_210.wav' 'audio/b116_240_270.wav'\n",
      " 'audio/b116_60_90.wav' 'audio/b116_30_60.wav' 'audio/b116_120_150.wav'\n",
      " 'audio/b116_0_30.wav' 'audio/b116_150_180.wav' 'audio/b116_90_120.wav'\n",
      " 'audio/b113_0_30.wav' 'audio/b113_210_240.wav' 'audio/b113_30_60.wav'\n",
      " 'audio/b113_150_180.wav' 'audio/b113_90_120.wav' 'audio/b113_240_270.wav'\n",
      " 'audio/b113_270_300.wav' 'audio/b113_120_150.wav' 'audio/b113_60_90.wav'\n",
      " 'audio/b113_180_210.wav' 'audio/a027_60_90.wav' 'audio/a027_0_30.wav'\n",
      " 'audio/a027_30_60.wav' 'audio/a027_180_210.wav' 'audio/a027_150_180.wav'\n",
      " 'audio/a027_90_120.wav' 'audio/a021_150_180.wav' 'audio/a021_90_120.wav'\n",
      " 'audio/a021_180_210.wav' 'audio/a021_30_60.wav' 'audio/a021_120_150.wav'\n",
      " 'audio/a021_0_30.wav' 'audio/a021_60_90.wav' 'audio/a022_0_30.wav'\n",
      " 'audio/a022_180_210.wav' 'audio/a022_150_180.wav' 'audio/a022_30_60.wav'\n",
      " 'audio/a022_120_150.wav' 'audio/a022_60_90.wav' 'audio/a022_90_120.wav'\n",
      " 'audio/b004_60_90.wav' 'audio/b004_90_120.wav' 'audio/b004_30_60.wav'\n",
      " 'audio/b004_0_30.wav' 'audio/b004_120_150.wav' 'audio/a009_60_90.wav'\n",
      " 'audio/a009_120_150.wav' 'audio/a009_0_30.wav' 'audio/a009_150_180.wav'\n",
      " 'audio/a009_180_210.wav' 'audio/a009_30_60.wav' 'audio/a009_90_120.wav'\n",
      " 'audio/b003_90_120.wav' 'audio/b003_0_30.wav' 'audio/b003_120_150.wav'\n",
      " 'audio/b003_30_60.wav' 'audio/b003_150_180.wav' 'audio/b003_60_90.wav'\n",
      " 'audio/b003_180_210.wav' 'audio/b060_90_120.wav' 'audio/b060_30_60.wav'\n",
      " 'audio/b060_60_90.wav' 'audio/b060_0_30.wav' 'audio/b067_60_90.wav'\n",
      " 'audio/b067_90_120.wav' 'audio/b067_0_30.wav' 'audio/b067_120_150.wav'\n",
      " 'audio/b067_150_180.wav' 'audio/a074_150_180.wav' 'audio/a074_0_30.wav'\n",
      " 'audio/a074_90_120.wav' 'audio/a074_240_270.wav' 'audio/a074_30_60.wav'\n",
      " 'audio/a074_120_150.wav' 'audio/a074_60_90.wav' 'audio/a074_210_240.wav'\n",
      " 'audio/a074_180_210.wav' 'audio/a154_0_30.wav' 'audio/a154_90_120.wav'\n",
      " 'audio/a154_270_300.wav' 'audio/a154_30_60.wav' 'audio/a154_120_150.wav'\n",
      " 'audio/a154_180_210.wav' 'audio/a154_60_90.wav' 'audio/a154_150_180.wav'\n",
      " 'audio/b078_120_150.wav' 'audio/b078_0_30.wav' 'audio/b078_60_90.wav'\n",
      " 'audio/b078_90_120.wav' 'audio/b078_150_180.wav' 'audio/b078_180_210.wav'\n",
      " 'audio/a152_180_210.wav' 'audio/a152_30_60.wav' 'audio/a152_210_240.wav'\n",
      " 'audio/a152_0_30.wav' 'audio/a152_60_90.wav' 'audio/a152_90_120.wav']\n"
     ]
    }
   ],
   "source": [
    "# Read data and preprocessing\n",
    "X_test = pd.read_csv('test_files.txt', header=None)[0].values\n",
    "data = pd.read_csv('audio/train.txt', header=None, sep='\\s+')\n",
    "X_train =  data[0].values\n",
    "y_train = pd.factorize(data[1])[0]\n",
    "print X_train\n",
    "#print y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_mfcc = 20\n",
    "def extract_feature(file_name):\n",
    "    X, sample_rate = librosa.load(file_name, sr = None)\n",
    "    S = librosa.feature.melspectrogram(y = X, sr = sample_rate, n_fft = 512, hop_length = 512)\n",
    "    mfcc = librosa.feature.mfcc(y=X, sr=sample_rate, S=librosa.power_to_db(S), n_mfcc = n_mfcc).T\n",
    "    return mfcc#,chroma,mel,contrast,tonnetz\n",
    "\n",
    "def parse_audio_files(files, file_labels):\n",
    "    features, labels = np.empty((0,n_mfcc)), np.empty(0)\n",
    "    for i in range(files.shape[0]):\n",
    "        try:\n",
    "            mfccs = extract_feature(files[i])\n",
    "            #print mfccs.shape\n",
    "        except Exception as e:\n",
    "            print \"Error encountered while parsing file: \", files[i]\n",
    "            continue\n",
    "        features = np.vstack([features, mfccs])\n",
    "        labels = np.append(labels, file_labels[i]*np.ones(mfccs.shape[0]))\n",
    "        print files[i]\n",
    "    return np.array(features), np.array(labels, dtype = np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "audio/b010_0_30.wav\n",
      "audio/b010_60_90.wav\n",
      "audio/b010_150_180.wav\n",
      "audio/b010_30_60.wav\n",
      "audio/b010_120_150.wav\n",
      "audio/b022_120_150.wav\n",
      "audio/b022_60_90.wav\n",
      "audio/b022_180_210.wav\n",
      "audio/b022_30_60.wav\n",
      "audio/b022_90_120.wav\n",
      "audio/b022_150_180.wav\n",
      "audio/b022_0_30.wav\n",
      "audio/b011_180_210.wav\n",
      "audio/b011_90_120.wav\n",
      "audio/b011_150_180.wav\n",
      "audio/b011_60_90.wav\n",
      "audio/b011_120_150.wav\n",
      "audio/b011_30_60.wav\n",
      "audio/b011_0_30.wav\n",
      "audio/a112_90_120.wav\n",
      "audio/a112_120_150.wav\n",
      "audio/a112_30_60.wav\n",
      "audio/a112_60_90.wav\n",
      "audio/a112_0_30.wav\n",
      "audio/b107_0_30.wav\n",
      "audio/b107_30_60.wav\n",
      "audio/b107_90_120.wav\n",
      "audio/b107_60_90.wav\n",
      "audio/b110_210_240.wav\n",
      "audio/b110_120_150.wav\n",
      "audio/b110_180_210.wav\n",
      "audio/b110_150_180.wav\n",
      "audio/b110_270_300.wav\n",
      "audio/b110_90_120.wav\n",
      "audio/b110_30_60.wav\n",
      "audio/b110_0_30.wav\n",
      "audio/b110_240_270.wav\n",
      "audio/b110_60_90.wav\n",
      "audio/a083_30_60.wav\n",
      "audio/a083_0_30.wav\n",
      "audio/a083_150_180.wav\n",
      "audio/a083_60_90.wav\n",
      "audio/a083_120_150.wav\n",
      "audio/a083_90_120.wav\n",
      "audio/a060_60_90.wav\n",
      "audio/a060_0_30.wav\n",
      "audio/a060_120_150.wav\n",
      "audio/a060_90_120.wav\n",
      "audio/a060_30_60.wav\n",
      "audio/b050_0_30.wav\n",
      "audio/b050_120_150.wav\n",
      "audio/b050_90_120.wav\n",
      "audio/b050_150_180.wav\n",
      "audio/b050_30_60.wav\n",
      "audio/b050_60_90.wav\n",
      "audio/b050_180_210.wav\n",
      "audio/b096_90_120.wav\n",
      "audio/b096_240_270.wav\n",
      "audio/b096_180_210.wav\n",
      "audio/b096_210_240.wav\n",
      "audio/b096_0_30.wav\n",
      "audio/b096_270_300.wav\n",
      "audio/b096_150_180.wav\n",
      "audio/b096_30_60.wav\n",
      "audio/b096_120_150.wav\n",
      "audio/a133_120_150.wav\n",
      "audio/a133_180_210.wav\n",
      "audio/a133_150_180.wav\n",
      "audio/a133_0_30.wav\n",
      "audio/a133_30_60.wav\n",
      "audio/a133_60_90.wav\n",
      "audio/a095_60_90.wav\n",
      "audio/a095_30_60.wav\n",
      "audio/a095_150_180.wav\n",
      "audio/a095_90_120.wav\n",
      "audio/a095_120_150.wav\n",
      "audio/b099_180_210.wav\n",
      "audio/b099_210_240.wav\n",
      "audio/b099_60_90.wav\n",
      "audio/b099_30_60.wav\n",
      "audio/b099_90_120.wav\n",
      "audio/b094_90_120.wav\n",
      "audio/b094_210_240.wav\n",
      "audio/b094_30_60.wav\n",
      "audio/b094_150_180.wav\n",
      "audio/b094_120_150.wav\n",
      "audio/b094_0_30.wav\n",
      "audio/a131_30_60.wav\n",
      "audio/a131_210_240.wav\n",
      "audio/a131_0_30.wav\n",
      "audio/a131_60_90.wav\n",
      "audio/a131_150_180.wav\n",
      "audio/a131_90_120.wav\n",
      "audio/a131_120_150.wav\n",
      "audio/a040_60_90.wav\n",
      "audio/a040_90_120.wav\n",
      "audio/a040_30_60.wav\n",
      "audio/a040_141_171.wav\n",
      "audio/a040_0_30.wav\n",
      "audio/a096_180_210.wav\n",
      "audio/a096_0_30.wav\n",
      "audio/a096_90_120.wav\n",
      "audio/a096_30_60.wav\n",
      "audio/a096_210_240.wav\n",
      "audio/a096_120_150.wav\n",
      "audio/a096_60_90.wav\n",
      "audio/a096_270_300.wav\n",
      "audio/a096_150_180.wav\n",
      "audio/a096_240_270.wav\n",
      "audio/a059_30_60.wav\n",
      "audio/a059_150_180.wav\n",
      "audio/a059_0_30.wav\n",
      "audio/a059_90_120.wav\n",
      "audio/a059_120_150.wav\n",
      "audio/a059_60_90.wav\n",
      "audio/b085_90_120.wav\n",
      "audio/b085_120_150.wav\n",
      "audio/b085_60_90.wav\n",
      "audio/b085_0_30.wav\n",
      "audio/b085_180_210.wav\n",
      "audio/b085_150_180.wav\n",
      "audio/b087_60_90.wav\n",
      "audio/b087_30_60.wav\n",
      "audio/b087_150_180.wav\n",
      "audio/b087_0_30.wav\n",
      "audio/b087_90_120.wav\n",
      "audio/b087_120_150.wav\n",
      "audio/a113_245_275.wav\n",
      "audio/a113_30_60.wav\n",
      "audio/a113_215_245.wav\n",
      "audio/a113_90_120.wav\n",
      "audio/a113_60_90.wav\n",
      "audio/a113_155_185.wav\n",
      "audio/a113_185_215.wav\n",
      "audio/a031_0_30.wav\n",
      "audio/a031_30_60.wav\n",
      "audio/a031_90_120.wav\n",
      "audio/a031_150_180.wav\n",
      "audio/a031_60_90.wav\n",
      "audio/a031_120_150.wav\n",
      "audio/b032_60_90.wav\n",
      "audio/b032_180_210.wav\n",
      "audio/b032_210_240.wav\n",
      "audio/b032_90_120.wav\n",
      "audio/b032_150_180.wav\n",
      "audio/b032_270_300.wav\n",
      "audio/b032_30_60.wav\n",
      "audio/b032_0_30.wav\n",
      "audio/b032_240_270.wav\n",
      "audio/b033_120_150.wav\n",
      "audio/b033_180_210.wav\n",
      "audio/b033_210_240.wav\n",
      "audio/b033_90_120.wav\n",
      "audio/b033_0_30.wav\n",
      "audio/b033_60_90.wav\n",
      "audio/b033_30_60.wav\n",
      "audio/b034_0_30.wav\n",
      "audio/b034_180_210.wav\n",
      "audio/b034_120_150.wav\n",
      "audio/b034_150_180.wav\n",
      "audio/b034_210_240.wav\n",
      "audio/b034_60_90.wav\n",
      "audio/b034_30_60.wav\n",
      "audio/b034_90_120.wav\n",
      "audio/b025_150_180.wav\n",
      "audio/b025_90_120.wav\n",
      "audio/b025_180_210.wav\n",
      "audio/b025_60_90.wav\n",
      "audio/b025_0_30.wav\n",
      "audio/b025_120_150.wav\n",
      "audio/b038_150_180.wav\n",
      "audio/b038_90_120.wav\n",
      "audio/b038_210_240.wav\n",
      "audio/b038_120_150.wav\n",
      "audio/b038_0_30.wav\n",
      "audio/b038_30_60.wav\n",
      "audio/b038_60_90.wav\n",
      "audio/b071_30_60.wav\n",
      "audio/b071_120_150.wav\n",
      "audio/b071_150_180.wav\n",
      "audio/b071_60_90.wav\n",
      "audio/b071_90_120.wav\n",
      "audio/a084_242_272.wav\n",
      "audio/a084_92_122.wav\n",
      "audio/a084_62_92.wav\n",
      "audio/a084_122_152.wav\n",
      "audio/a084_212_242.wav\n",
      "audio/a084_152_182.wav\n",
      "audio/a084_182_212.wav\n",
      "audio/a156_210_240.wav\n",
      "audio/a156_60_90.wav\n",
      "audio/a156_240_270.wav\n",
      "audio/a156_120_150.wav\n",
      "audio/a156_0_30.wav\n",
      "audio/a156_90_120.wav\n",
      "audio/a156_270_300.wav\n",
      "audio/a099_240_270.wav\n",
      "audio/a099_180_210.wav\n",
      "audio/a099_60_90.wav\n",
      "audio/a099_150_180.wav\n",
      "audio/a099_210_240.wav\n",
      "audio/a099_0_30.wav\n",
      "audio/a099_120_150.wav\n",
      "audio/b115_120_150.wav\n",
      "audio/b115_60_90.wav\n",
      "audio/b115_240_270.wav\n",
      "audio/b115_210_240.wav\n",
      "audio/b115_0_30.wav\n",
      "audio/b115_180_210.wav\n",
      "audio/b115_30_60.wav\n",
      "audio/a120_240_270.wav\n",
      "audio/a120_210_240.wav\n",
      "audio/a120_120_150.wav\n",
      "audio/a120_0_30.wav\n",
      "audio/a120_150_180.wav\n",
      "audio/a018_90_120.wav\n",
      "audio/a018_30_60.wav\n",
      "audio/a018_0_30.wav\n",
      "audio/a018_180_210.wav\n",
      "audio/a018_150_180.wav\n",
      "audio/a018_120_150.wav\n",
      "audio/a018_60_90.wav\n",
      "audio/a017_120_150.wav\n",
      "audio/a017_60_90.wav\n",
      "audio/a017_0_30.wav\n",
      "audio/a017_150_180.wav\n",
      "audio/a017_30_60.wav\n",
      "audio/a017_90_120.wav\n",
      "audio/a017_180_210.wav\n",
      "audio/b014_0_30.wav\n",
      "audio/b014_120_150.wav\n",
      "audio/b014_30_60.wav\n",
      "audio/b014_150_180.wav\n",
      "audio/b014_60_90.wav\n",
      "audio/b014_90_120.wav\n",
      "audio/b008_120_150.wav\n",
      "audio/b008_90_120.wav\n",
      "audio/b008_0_30.wav\n",
      "audio/b008_180_210.wav\n",
      "audio/b008_60_90.wav\n",
      "audio/b008_150_180.wav\n",
      "audio/a001_150_180.wav\n",
      "audio/a001_0_30.wav\n",
      "audio/a001_60_90.wav\n",
      "audio/a001_90_120.wav\n",
      "audio/a001_30_60.wav\n",
      "audio/a001_120_150.wav\n",
      "audio/b006_150_180.wav\n",
      "audio/b006_90_120.wav\n",
      "audio/b006_30_60.wav\n",
      "audio/b006_180_210.wav\n",
      "audio/b006_0_30.wav\n",
      "audio/b006_60_90.wav\n",
      "audio/b006_120_150.wav\n",
      "audio/b065_144_174.wav\n",
      "audio/b065_0_30.wav\n",
      "audio/b065_84_114.wav\n",
      "audio/b065_174_204.wav\n",
      "audio/b065_54_84.wav\n",
      "audio/b065_204_234.wav\n",
      "audio/b065_114_144.wav\n",
      "audio/a145_180_210.wav\n",
      "audio/a145_60_90.wav\n",
      "audio/a145_150_180.wav\n",
      "audio/a145_120_150.wav\n",
      "audio/a145_210_240.wav\n",
      "audio/a145_90_120.wav\n",
      "audio/a145_240_270.wav\n",
      "audio/a145_30_60.wav\n",
      "audio/b061_0_30.wav\n",
      "audio/b061_60_90.wav\n",
      "audio/b061_30_60.wav\n",
      "audio/a148_120_150.wav\n",
      "audio/a148_270_300.wav\n",
      "audio/a148_60_90.wav\n",
      "audio/a148_180_210.wav\n",
      "audio/a148_240_270.wav\n",
      "audio/b082_90_120.wav\n",
      "audio/b082_0_30.wav\n",
      "audio/b082_120_150.wav\n",
      "audio/b082_60_90.wav\n",
      "audio/b082_150_180.wav\n",
      "audio/a076_60_90.wav\n",
      "audio/a076_270_300.wav\n",
      "audio/a076_180_210.wav\n",
      "audio/a076_90_120.wav\n",
      "audio/a076_240_270.wav\n",
      "audio/a076_120_150.wav\n",
      "audio/a076_210_240.wav\n",
      "audio/a076_30_60.wav\n",
      "audio/a016_120_150.wav\n",
      "audio/a016_0_30.wav\n",
      "audio/a016_180_210.wav\n",
      "audio/a016_150_180.wav\n",
      "audio/a016_90_120.wav\n",
      "audio/a016_60_90.wav\n",
      "audio/a016_30_60.wav\n",
      "audio/a006_30_60.wav\n",
      "audio/a006_150_180.wav\n",
      "audio/a006_90_120.wav\n",
      "audio/a006_60_90.wav\n",
      "audio/a006_0_30.wav\n",
      "audio/a023_30_60.wav\n",
      "audio/a023_150_180.wav\n",
      "audio/a023_180_210.wav\n",
      "audio/a023_0_30.wav\n",
      "audio/a023_60_90.wav\n",
      "audio/a023_90_120.wav\n",
      "audio/a023_120_150.wav\n",
      "audio/b112_203_233.wav\n",
      "audio/b112_113_143.wav\n",
      "audio/b112_30_60.wav\n",
      "audio/b112_60_90.wav\n",
      "audio/b112_173_203.wav\n",
      "audio/b112_143_173.wav\n",
      "audio/b112_0_30.wav\n",
      "audio/b109_90_120.wav\n",
      "audio/b109_30_60.wav\n",
      "audio/b109_0_30.wav\n",
      "audio/b109_60_90.wav\n",
      "audio/b109_180_210.wav\n",
      "audio/b109_210_240.wav\n",
      "audio/b109_240_270.wav\n",
      "audio/b109_120_150.wav\n",
      "audio/b109_150_180.wav\n",
      "audio/b108_90_120.wav\n",
      "audio/b108_0_30.wav\n",
      "audio/b108_60_90.wav\n",
      "audio/b108_30_60.wav\n",
      "audio/a130_90_120.wav\n",
      "audio/a130_60_90.wav\n",
      "audio/a130_150_180.wav\n",
      "audio/a130_180_210.wav\n",
      "audio/a130_210_240.wav\n",
      "audio/a130_0_30.wav\n",
      "audio/a130_120_150.wav\n",
      "audio/a130_30_60.wav\n",
      "audio/a109_210_240.wav\n",
      "audio/a109_0_30.wav\n",
      "audio/a109_150_180.wav\n",
      "audio/a109_90_120.wav\n",
      "audio/a109_60_90.wav\n",
      "audio/a109_120_150.wav\n",
      "audio/a109_180_210.wav\n",
      "audio/a082_30_60.wav\n",
      "audio/a082_150_180.wav\n",
      "audio/a082_90_120.wav\n",
      "audio/a082_60_90.wav\n",
      "audio/a082_120_150.wav\n",
      "audio/a101_30_60.wav\n",
      "audio/a101_150_180.wav\n",
      "audio/a101_90_120.wav\n",
      "audio/a101_180_210.wav\n",
      "audio/a101_0_30.wav\n",
      "audio/a137_60_90.wav\n",
      "audio/a137_90_120.wav\n",
      "audio/a137_0_30.wav\n",
      "audio/a137_150_180.wav\n",
      "audio/a137_240_270.wav\n",
      "audio/a137_270_300.wav\n",
      "audio/a137_180_210.wav\n",
      "audio/a137_30_60.wav\n",
      "audio/a137_210_240.wav\n",
      "audio/b045_30_60.wav\n",
      "audio/b045_180_210.wav\n",
      "audio/b045_0_30.wav\n",
      "audio/b045_120_150.wav\n",
      "audio/b045_90_120.wav\n",
      "audio/b045_60_90.wav\n",
      "audio/a128_131_161.wav\n",
      "audio/a128_101_131.wav\n",
      "audio/a128_41_71.wav\n",
      "audio/a128_11_41.wav\n",
      "audio/a128_161_191.wav\n",
      "audio/a128_191_221.wav\n",
      "audio/a128_71_101.wav\n",
      "audio/b098_0_30.wav\n",
      "audio/b098_30_60.wav\n",
      "audio/b098_120_150.wav\n",
      "audio/b098_180_210.wav\n",
      "audio/b098_60_90.wav\n",
      "audio/b098_150_180.wav\n",
      "audio/b098_210_240.wav\n",
      "audio/b098_90_120.wav\n",
      "audio/b093_180_210.wav\n",
      "audio/b093_30_60.wav\n",
      "audio/b093_120_150.wav\n",
      "audio/b093_90_120.wav\n",
      "audio/b093_60_90.wav\n",
      "audio/b093_0_30.wav\n",
      "audio/b093_150_180.wav\n",
      "audio/a057_150_180.wav\n",
      "audio/a057_30_60.wav\n",
      "audio/a057_120_150.wav\n",
      "audio/a057_60_90.wav\n",
      "audio/a057_0_30.wav\n",
      "audio/a057_90_120.wav\n",
      "audio/a098_30_60.wav\n",
      "audio/a098_150_180.wav\n",
      "audio/a098_90_120.wav\n",
      "audio/a098_240_270.wav\n",
      "audio/a098_210_240.wav\n",
      "audio/a098_270_300.wav\n",
      "audio/a098_180_210.wav\n",
      "audio/a098_0_30.wav\n",
      "audio/a098_120_150.wav\n",
      "audio/a098_60_90.wav\n",
      "audio/a069_30_60.wav\n",
      "audio/a069_60_90.wav\n",
      "audio/a069_120_150.wav\n",
      "audio/a069_90_120.wav\n",
      "audio/a069_0_30.wav\n",
      "audio/a105_270_300.wav\n",
      "audio/a105_210_240.wav\n",
      "audio/a105_90_120.wav\n",
      "audio/a105_30_60.wav\n",
      "audio/a105_150_180.wav\n",
      "audio/a105_0_30.wav\n",
      "audio/a105_180_210.wav\n",
      "audio/a105_120_150.wav\n",
      "audio/b103_120_150.wav\n",
      "audio/b103_0_30.wav\n",
      "audio/b103_90_120.wav\n",
      "audio/b103_60_90.wav\n",
      "audio/b103_30_60.wav\n",
      "audio/b106_30_60.wav\n",
      "audio/b106_0_30.wav\n",
      "audio/b106_90_120.wav\n",
      "audio/b106_120_150.wav\n",
      "audio/b106_150_180.wav\n",
      "audio/b106_60_90.wav\n",
      "audio/b030_90_120.wav\n",
      "audio/b030_0_30.wav\n",
      "audio/b030_270_300.wav\n",
      "audio/b030_30_60.wav\n",
      "audio/b030_210_240.wav\n",
      "audio/b030_150_180.wav\n",
      "audio/b030_240_270.wav\n",
      "audio/b030_120_150.wav\n",
      "audio/b030_180_210.wav\n",
      "audio/b030_60_90.wav\n",
      "audio/b031_60_90.wav\n",
      "audio/b031_210_240.wav\n",
      "audio/b031_180_210.wav\n",
      "audio/b031_30_60.wav\n",
      "audio/b031_0_30.wav\n",
      "audio/b031_120_150.wav\n",
      "audio/b031_90_120.wav\n",
      "audio/b031_150_180.wav\n",
      "audio/b036_60_90.wav\n",
      "audio/b036_210_240.wav\n",
      "audio/b036_0_30.wav\n",
      "audio/b036_90_120.wav\n",
      "audio/b036_180_210.wav\n",
      "audio/b036_150_180.wav\n",
      "audio/b039_120_150.wav\n",
      "audio/b039_150_180.wav\n",
      "audio/b039_60_90.wav\n",
      "audio/b039_90_120.wav\n",
      "audio/b039_180_210.wav\n",
      "audio/b039_0_30.wav\n",
      "audio/b039_30_60.wav\n",
      "audio/b039_210_240.wav\n",
      "audio/b047_90_120.wav\n",
      "audio/b047_60_90.wav\n",
      "audio/b047_30_60.wav\n",
      "audio/b047_0_30.wav\n",
      "audio/b047_120_150.wav\n",
      "audio/a158_60_90.wav\n",
      "audio/a158_0_30.wav\n",
      "audio/a158_30_60.wav\n",
      "audio/b075_120_150.wav\n",
      "audio/b075_0_30.wav\n",
      "audio/b075_60_90.wav\n",
      "audio/b075_150_180.wav\n",
      "audio/b075_90_120.wav\n",
      "audio/b075_30_60.wav\n",
      "audio/a155_270_300.wav\n",
      "audio/a155_150_180.wav\n",
      "audio/a155_210_240.wav\n",
      "audio/a155_240_270.wav\n",
      "audio/a155_180_210.wav\n",
      "audio/a155_60_90.wav\n",
      "audio/a155_120_150.wav\n",
      "audio/a155_30_60.wav\n",
      "audio/a155_0_30.wav\n",
      "audio/a155_90_120.wav\n",
      "audio/b116_180_210.wav\n",
      "audio/b116_240_270.wav\n",
      "audio/b116_60_90.wav\n",
      "audio/b116_30_60.wav\n",
      "audio/b116_120_150.wav\n",
      "audio/b116_0_30.wav\n",
      "audio/b116_150_180.wav\n",
      "audio/b116_90_120.wav\n",
      "audio/b113_0_30.wav\n",
      "audio/b113_210_240.wav\n",
      "audio/b113_30_60.wav\n",
      "audio/b113_150_180.wav\n",
      "audio/b113_90_120.wav\n",
      "audio/b113_240_270.wav\n",
      "audio/b113_270_300.wav\n",
      "audio/b113_120_150.wav\n",
      "audio/b113_60_90.wav\n",
      "audio/b113_180_210.wav\n",
      "audio/a027_60_90.wav\n",
      "audio/a027_0_30.wav\n",
      "audio/a027_30_60.wav\n",
      "audio/a027_180_210.wav\n",
      "audio/a027_150_180.wav\n",
      "audio/a027_90_120.wav\n",
      "audio/a021_150_180.wav\n",
      "audio/a021_90_120.wav\n",
      "audio/a021_180_210.wav\n",
      "audio/a021_30_60.wav\n",
      "audio/a021_120_150.wav\n",
      "audio/a021_0_30.wav\n",
      "audio/a021_60_90.wav\n",
      "audio/a022_0_30.wav\n",
      "audio/a022_180_210.wav\n",
      "audio/a022_150_180.wav\n",
      "audio/a022_30_60.wav\n",
      "audio/a022_120_150.wav\n",
      "audio/a022_60_90.wav\n",
      "audio/a022_90_120.wav\n",
      "audio/b004_60_90.wav\n",
      "audio/b004_90_120.wav\n",
      "audio/b004_30_60.wav\n",
      "audio/b004_0_30.wav\n",
      "audio/b004_120_150.wav\n",
      "audio/a009_60_90.wav\n",
      "audio/a009_120_150.wav\n",
      "audio/a009_0_30.wav\n",
      "audio/a009_150_180.wav\n",
      "audio/a009_180_210.wav\n",
      "audio/a009_30_60.wav\n",
      "audio/a009_90_120.wav\n",
      "audio/b003_90_120.wav\n",
      "audio/b003_0_30.wav\n",
      "audio/b003_120_150.wav\n",
      "audio/b003_30_60.wav\n",
      "audio/b003_150_180.wav\n",
      "audio/b003_60_90.wav\n",
      "audio/b003_180_210.wav\n",
      "audio/b060_90_120.wav\n",
      "audio/b060_30_60.wav\n",
      "audio/b060_60_90.wav\n",
      "audio/b060_0_30.wav\n",
      "audio/b067_60_90.wav\n",
      "audio/b067_90_120.wav\n",
      "audio/b067_0_30.wav\n",
      "audio/b067_120_150.wav\n",
      "audio/b067_150_180.wav\n",
      "audio/a074_150_180.wav\n",
      "audio/a074_0_30.wav\n",
      "audio/a074_90_120.wav\n",
      "audio/a074_240_270.wav\n",
      "audio/a074_30_60.wav\n",
      "audio/a074_120_150.wav\n",
      "audio/a074_60_90.wav\n",
      "audio/a074_210_240.wav\n",
      "audio/a074_180_210.wav\n",
      "audio/a154_0_30.wav\n",
      "audio/a154_90_120.wav\n",
      "audio/a154_270_300.wav\n",
      "audio/a154_30_60.wav\n",
      "audio/a154_120_150.wav\n",
      "audio/a154_180_210.wav\n",
      "audio/a154_60_90.wav\n",
      "audio/a154_150_180.wav\n",
      "audio/b078_120_150.wav\n",
      "audio/b078_0_30.wav\n",
      "audio/b078_60_90.wav\n",
      "audio/b078_90_120.wav\n",
      "audio/b078_150_180.wav\n",
      "audio/b078_180_210.wav\n",
      "audio/a152_180_210.wav\n",
      "audio/a152_30_60.wav\n",
      "audio/a152_210_240.wav\n",
      "audio/a152_0_30.wav\n",
      "audio/a152_60_90.wav\n",
      "audio/a152_90_120.wav\n",
      "(545916, 20)\n",
      "[ 0  0  0 ..., 14 14 14]\n"
     ]
    }
   ],
   "source": [
    "ft, lb = parse_audio_files(X_train, y_train)\n",
    "print ft.shape\n",
    "print lb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rui/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/rui/anaconda/lib/python2.7/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 3.27946367\n",
      "Iteration 1, loss = 3.29846243\n",
      "Iteration 1, loss = 3.26561363\n",
      "Iteration 1, loss = 3.25082357\n",
      "Iteration 2, loss = 2.04563983\n",
      "Iteration 2, loss = 2.04960629\n",
      "Iteration 2, loss = 2.02911885\n",
      "Iteration 2, loss = 2.03590766\n",
      "Iteration 3, loss = 1.68956481\n",
      "Iteration 3, loss = 1.68965393\n",
      "Iteration 3, loss = 1.66820973\n",
      "Iteration 3, loss = 1.68749659\n",
      "Iteration 4, loss = 1.55637130\n",
      "Iteration 4, loss = 1.55468670\n",
      "Iteration 4, loss = 1.53424281\n",
      "Iteration 4, loss = 1.56348838\n",
      "Iteration 5, loss = 1.50608184\n",
      "Iteration 5, loss = 1.50388101\n",
      "Iteration 5, loss = 1.48223669\n",
      "Iteration 5, loss = 1.51390161\n",
      "Iteration 6, loss = 1.47827100\n",
      "Iteration 6, loss = 1.47984241\n",
      "Iteration 6, loss = 1.45933582\n",
      "Iteration 6, loss = 1.49009628\n",
      "Iteration 7, loss = 1.46817666\n",
      "Iteration 7, loss = 1.46391490\n",
      "Iteration 7, loss = 1.44593921\n",
      "Iteration 7, loss = 1.47536864\n",
      "Iteration 8, loss = 1.45548255\n",
      "Iteration 8, loss = 1.43544307\n",
      "Iteration 8, loss = 1.45206929\n",
      "Iteration 8, loss = 1.46690577\n",
      "Iteration 9, loss = 1.44755890\n",
      "Iteration 9, loss = 1.42675928\n",
      "Iteration 9, loss = 1.45878215\n",
      "Iteration 9, loss = 1.44116334\n",
      "Iteration 10, loss = 1.44304111\n",
      "Iteration 10, loss = 1.41981902\n",
      "Iteration 10, loss = 1.45098284\n",
      "Iteration 10, loss = 1.43298236\n",
      "Iteration 11, loss = 1.43535290\n",
      "Iteration 11, loss = 1.41393371\n",
      "Iteration 11, loss = 1.44553654\n",
      "Iteration 11, loss = 1.42709798\n",
      "Iteration 12, loss = 1.42912232\n",
      "Iteration 12, loss = 1.40818043\n",
      "Iteration 12, loss = 1.44037577\n",
      "Iteration 12, loss = 1.41952990\n",
      "Iteration 13, loss = 1.42668874\n",
      "Iteration 13, loss = 1.40090402\n",
      "Iteration 13, loss = 1.43489695\n",
      "Iteration 13, loss = 1.41532322\n",
      "Iteration 14, loss = 1.42063259\n",
      "Iteration 14, loss = 1.39816575\n",
      "Iteration 14, loss = 1.43197914\n",
      "Iteration 14, loss = 1.41186079\n",
      "Iteration 15, loss = 1.41851978\n",
      "Iteration 15, loss = 1.39257881\n",
      "Iteration 15, loss = 1.42872874\n",
      "Iteration 15, loss = 1.40828562\n",
      "Iteration 16, loss = 1.41439293\n",
      "Iteration 16, loss = 1.40464161\n",
      "Iteration 16, loss = 1.39114476\n",
      "Iteration 16, loss = 1.42412602\n",
      "Iteration 17, loss = 1.41277921\n",
      "Iteration 17, loss = 1.40021594\n",
      "Iteration 17, loss = 1.38715661\n",
      "Iteration 17, loss = 1.42287625\n",
      "Iteration 18, loss = 1.40866517\n",
      "Iteration 18, loss = 1.38337620\n",
      "Iteration 18, loss = 1.39686308\n",
      "Iteration 18, loss = 1.41973010\n",
      "Iteration 19, loss = 1.40700020\n",
      "Iteration 19, loss = 1.38213501\n",
      "Iteration 19, loss = 1.39668618\n",
      "Iteration 19, loss = 1.41818645\n",
      "Iteration 20, loss = 1.40480311\n",
      "Iteration 20, loss = 1.37935780\n",
      "Iteration 20, loss = 1.39342740\n",
      "Iteration 20, loss = 1.41527589\n",
      "Iteration 21, loss = 1.40268350\n",
      "Iteration 21, loss = 1.37641820\n",
      "Iteration 21, loss = 1.39162849\n",
      "Iteration 21, loss = 1.41312429\n",
      "Iteration 22, loss = 1.37463862\n",
      "Iteration 22, loss = 1.39981216\n",
      "Iteration 22, loss = 1.38896210\n",
      "Iteration 22, loss = 1.41109936\n",
      "Iteration 23, loss = 1.37418081\n",
      "Iteration 23, loss = 1.39947468\n",
      "Iteration 23, loss = 1.38654194\n",
      "Iteration 23, loss = 1.40968031\n",
      "Iteration 24, loss = 1.37159424\n",
      "Iteration 24, loss = 1.39688461\n",
      "Iteration 24, loss = 1.38496104\n",
      "Iteration 24, loss = 1.40783219\n",
      "Iteration 25, loss = 1.36963713\n",
      "Iteration 25, loss = 1.39521272\n",
      "Iteration 25, loss = 1.38343173\n",
      "Iteration 25, loss = 1.40595976\n",
      "Iteration 26, loss = 1.39339050\n",
      "Iteration 26, loss = 1.37073601\n",
      "Iteration 26, loss = 1.38233017\n",
      "Iteration 26, loss = 1.40405742\n",
      "Iteration 27, loss = 1.39157454\n",
      "Iteration 27, loss = 1.36724641\n",
      "Iteration 27, loss = 1.38094996\n",
      "Iteration 27, loss = 1.40260360\n",
      "Iteration 28, loss = 1.39048845\n",
      "Iteration 28, loss = 1.36620860\n",
      "Iteration 28, loss = 1.37887453\n",
      "Iteration 28, loss = 1.40053869\n",
      "Iteration 29, loss = 1.38836564\n",
      "Iteration 29, loss = 1.36357259\n",
      "Iteration 29, loss = 1.37752946\n",
      "Iteration 29, loss = 1.40018694\n",
      "Iteration 30, loss = 1.38812335\n",
      "Iteration 30, loss = 1.36297659\n",
      "Iteration 30, loss = 1.37704861\n",
      "Iteration 30, loss = 1.39858046\n",
      "Iteration 31, loss = 1.38668296\n",
      "Iteration 31, loss = 1.36280834\n",
      "Iteration 31, loss = 1.37447547\n",
      "Iteration 31, loss = 1.39675561\n",
      "Iteration 32, loss = 1.38599914\n",
      "Iteration 32, loss = 1.36224174\n",
      "Iteration 32, loss = 1.37362081\n",
      "Iteration 32, loss = 1.39568770\n",
      "Iteration 33, loss = 1.38397718\n",
      "Iteration 33, loss = 1.36144851\n",
      "Iteration 33, loss = 1.37233909\n",
      "Iteration 33, loss = 1.39518921\n",
      "Iteration 34, loss = 1.36110049\n",
      "Iteration 34, loss = 1.38283573\n",
      "Iteration 34, loss = 1.37178194\n",
      "Iteration 34, loss = 1.39233527\n",
      "Iteration 35, loss = 1.38126577\n",
      "Iteration 35, loss = 1.35960434\n",
      "Iteration 35, loss = 1.36958253\n",
      "Iteration 35, loss = 1.39231634\n",
      "Iteration 36, loss = 1.35827975\n",
      "Iteration 36, loss = 1.38067675\n",
      "Iteration 36, loss = 1.36978951\n",
      "Iteration 36, loss = 1.39085978\n",
      "Iteration 37, loss = 1.35849325\n",
      "Iteration 37, loss = 1.37965293\n",
      "Iteration 37, loss = 1.36740909\n",
      "Iteration 37, loss = 1.39040805\n",
      "Iteration 38, loss = 1.37974157\n",
      "Iteration 38, loss = 1.35782974\n",
      "Iteration 38, loss = 1.36785121\n",
      "Iteration 38, loss = 1.38838273\n",
      "Iteration 39, loss = 1.37778743\n",
      "Iteration 39, loss = 1.35580086\n",
      "Iteration 39, loss = 1.36720884\n",
      "Iteration 39, loss = 1.38763342\n",
      "Iteration 40, loss = 1.37706639\n",
      "Iteration 40, loss = 1.35624099\n",
      "Iteration 40, loss = 1.36598292\n",
      "Iteration 40, loss = 1.38795314\n",
      "Iteration 41, loss = 1.37670062\n",
      "Iteration 41, loss = 1.35555557\n",
      "Iteration 41, loss = 1.36524121\n",
      "Iteration 41, loss = 1.38695751\n",
      "Iteration 42, loss = 1.35428435\n",
      "Iteration 42, loss = 1.37589729\n",
      "Iteration 42, loss = 1.36434919\n",
      "Iteration 42, loss = 1.38572161\n",
      "Iteration 43, loss = 1.35344929\n",
      "Iteration 43, loss = 1.37466476\n",
      "Iteration 43, loss = 1.36334322\n",
      "Iteration 43, loss = 1.38483210\n",
      "Iteration 44, loss = 1.35356392\n",
      "Iteration 44, loss = 1.37501361\n",
      "Iteration 44, loss = 1.36345430\n",
      "Iteration 44, loss = 1.38348356\n",
      "Iteration 45, loss = 1.35280126\n",
      "Iteration 45, loss = 1.37351239\n",
      "Iteration 45, loss = 1.36196896\n",
      "Iteration 45, loss = 1.38480756\n",
      "Iteration 46, loss = 1.35190393\n",
      "Iteration 46, loss = 1.37363782\n",
      "Iteration 46, loss = 1.36171178\n",
      "Iteration 46, loss = 1.38173820\n",
      "Iteration 47, loss = 1.35284630\n",
      "Iteration 47, loss = 1.37270239\n",
      "Iteration 47, loss = 1.36026686\n",
      "Iteration 47, loss = 1.38241325\n",
      "Iteration 48, loss = 1.35184501\n",
      "Iteration 48, loss = 1.37230338\n",
      "Iteration 48, loss = 1.36027598\n",
      "Iteration 48, loss = 1.38073145\n",
      "Iteration 49, loss = 1.35121561\n",
      "Iteration 49, loss = 1.37027981\n",
      "Iteration 49, loss = 1.35924711\n",
      "Iteration 49, loss = 1.37970603\n",
      "Iteration 50, loss = 1.35023078\n",
      "Iteration 50, loss = 1.37101672\n",
      "Iteration 50, loss = 1.35957678\n",
      "Iteration 50, loss = 1.38043884\n",
      "Iteration 51, loss = 1.35043959\n",
      "Iteration 51, loss = 1.37041860\n",
      "Iteration 51, loss = 1.35842400\n",
      "Iteration 51, loss = 1.37973547\n",
      "Iteration 52, loss = 1.34895856\n",
      "Iteration 52, loss = 1.36906834\n",
      "Iteration 52, loss = 1.35746710\n",
      "Iteration 52, loss = 1.37893697\n",
      "Iteration 53, loss = 1.34865610\n",
      "Iteration 53, loss = 1.36898572\n",
      "Iteration 53, loss = 1.35741270\n",
      "Iteration 53, loss = 1.37836081\n",
      "Iteration 54, loss = 1.34811822\n",
      "Iteration 54, loss = 1.36826456\n",
      "Iteration 54, loss = 1.35746907\n",
      "Iteration 54, loss = 1.37692153\n",
      "Iteration 55, loss = 1.34747704\n",
      "Iteration 55, loss = 1.36843011\n",
      "Iteration 55, loss = 1.35615863\n",
      "Iteration 55, loss = 1.37776402\n",
      "Iteration 56, loss = 1.34766034\n",
      "Iteration 56, loss = 1.36723336\n",
      "Iteration 56, loss = 1.35542536\n",
      "Iteration 56, loss = 1.37687806\n",
      "Iteration 57, loss = 1.34704100\n",
      "Iteration 57, loss = 1.36695008\n",
      "Iteration 57, loss = 1.35566988\n",
      "Iteration 57, loss = 1.37651295\n",
      "Iteration 58, loss = 1.34676896\n",
      "Iteration 58, loss = 1.36572430\n",
      "Iteration 58, loss = 1.35444474\n",
      "Iteration 58, loss = 1.37585691\n",
      "Iteration 59, loss = 1.34572553\n",
      "Iteration 59, loss = 1.36550241\n",
      "Iteration 59, loss = 1.35509406\n",
      "Iteration 59, loss = 1.37757427\n",
      "Iteration 60, loss = 1.34669158\n",
      "Iteration 60, loss = 1.36572081\n",
      "Iteration 60, loss = 1.35421413\n",
      "Iteration 60, loss = 1.37536788\n",
      "Iteration 61, loss = 1.34571324\n",
      "Iteration 61, loss = 1.36495950\n",
      "Iteration 61, loss = 1.35289897\n",
      "Iteration 62, loss = 1.34495755\n",
      "Iteration 61, loss = 1.37444671\n",
      "Iteration 62, loss = 1.36351000\n",
      "Iteration 62, loss = 1.35393141\n",
      "Iteration 63, loss = 1.34467316\n",
      "Iteration 62, loss = 1.37344996\n",
      "Iteration 63, loss = 1.36442610\n",
      "Iteration 63, loss = 1.35273715\n",
      "Iteration 64, loss = 1.34467441\n",
      "Iteration 63, loss = 1.37399385\n",
      "Iteration 64, loss = 1.36308545\n",
      "Iteration 64, loss = 1.35204088\n",
      "Iteration 65, loss = 1.34433990\n",
      "Iteration 64, loss = 1.37270353\n",
      "Iteration 65, loss = 1.36257099\n",
      "Iteration 65, loss = 1.35279646\n",
      "Iteration 66, loss = 1.34419970\n",
      "Iteration 65, loss = 1.37143592\n",
      "Iteration 66, loss = 1.36291841\n",
      "Iteration 66, loss = 1.35178458\n",
      "Iteration 67, loss = 1.34365334\n",
      "Iteration 66, loss = 1.37165647\n",
      "Iteration 67, loss = 1.36221106\n",
      "Iteration 67, loss = 1.35133760\n",
      "Iteration 68, loss = 1.34376667\n",
      "Iteration 67, loss = 1.37162489\n",
      "Iteration 68, loss = 1.36140489\n",
      "Iteration 68, loss = 1.35071840\n",
      "Iteration 69, loss = 1.34282086\n",
      "Iteration 68, loss = 1.37089379\n",
      "Iteration 69, loss = 1.36160901\n",
      "Iteration 69, loss = 1.34966356\n",
      "Iteration 70, loss = 1.34266042\n",
      "Iteration 69, loss = 1.37112238\n",
      "Iteration 70, loss = 1.36080768\n",
      "Iteration 70, loss = 1.35002621\n",
      "Iteration 71, loss = 1.34385031\n",
      "Iteration 70, loss = 1.37055604\n",
      "Iteration 71, loss = 1.36089923\n",
      "Iteration 71, loss = 1.34951941\n",
      "Iteration 72, loss = 1.34279689\n",
      "Iteration 71, loss = 1.37045937\n",
      "Iteration 72, loss = 1.36096596\n",
      "Iteration 72, loss = 1.35064757\n",
      "Iteration 73, loss = 1.34185696\n",
      "Iteration 72, loss = 1.37009275\n",
      "Iteration 73, loss = 1.35900169\n",
      "Iteration 73, loss = 1.34944270\n",
      "Iteration 74, loss = 1.34160425\n",
      "Iteration 73, loss = 1.36986489\n",
      "Iteration 74, loss = 1.35957448\n",
      "Iteration 74, loss = 1.34987756\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 75, loss = 1.34132463\n",
      "Iteration 74, loss = 1.37000533\n",
      "Iteration 1, loss = 3.27671245\n",
      "Iteration 75, loss = 1.35849232\n",
      "Iteration 76, loss = 1.34112379\n",
      "Iteration 2, loss = 2.02690205\n",
      "Iteration 75, loss = 1.36874770\n",
      "Iteration 76, loss = 1.35892110\n",
      "Iteration 77, loss = 1.34063034\n",
      "Iteration 3, loss = 1.67376053\n",
      "Iteration 76, loss = 1.36841488\n",
      "Iteration 77, loss = 1.35774036\n",
      "Iteration 78, loss = 1.34124066\n",
      "Iteration 4, loss = 1.54868423\n",
      "Iteration 77, loss = 1.36830389\n",
      "Iteration 78, loss = 1.35746949\n",
      "Iteration 5, loss = 1.50100849\n",
      "Iteration 79, loss = 1.34080107\n",
      "Iteration 79, loss = 1.35811508\n",
      "Iteration 78, loss = 1.36723705\n",
      "Iteration 6, loss = 1.48125626\n",
      "Iteration 80, loss = 1.33981272\n",
      "Iteration 80, loss = 1.35674219\n",
      "Iteration 79, loss = 1.36770561\n",
      "Iteration 7, loss = 1.46620168\n",
      "Iteration 81, loss = 1.33981233\n",
      "Iteration 81, loss = 1.35640415\n",
      "Iteration 80, loss = 1.36740529\n",
      "Iteration 8, loss = 1.45493872\n",
      "Iteration 82, loss = 1.33894195\n",
      "Iteration 82, loss = 1.35660123\n",
      "Iteration 81, loss = 1.36629410\n",
      "Iteration 83, loss = 1.33955873\n",
      "Iteration 9, loss = 1.44704865\n",
      "Iteration 83, loss = 1.35695093\n",
      "Iteration 82, loss = 1.36704799\n",
      "Iteration 84, loss = 1.33970862\n",
      "Iteration 10, loss = 1.44042371\n",
      "Iteration 84, loss = 1.35636515\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 83, loss = 1.36565394\n",
      "Iteration 85, loss = 1.33957639\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 11, loss = 1.43267709\n",
      "Iteration 1, loss = 4.78183806\n",
      "Iteration 84, loss = 1.36510803\n",
      "Iteration 1, loss = 4.77411167\n",
      "Iteration 2, loss = 2.42672874\n",
      "Iteration 12, loss = 1.42657965\n",
      "Iteration 2, loss = 2.41653620\n",
      "Iteration 85, loss = 1.36653237\n",
      "Iteration 3, loss = 1.97913034\n",
      "Iteration 3, loss = 1.95850332\n",
      "Iteration 13, loss = 1.42278394\n",
      "Iteration 86, loss = 1.36557055\n",
      "Iteration 4, loss = 1.88237378\n",
      "Iteration 4, loss = 1.85468011\n",
      "Iteration 14, loss = 1.41760605\n",
      "Iteration 5, loss = 1.84900025\n",
      "Iteration 87, loss = 1.36464564\n",
      "Iteration 5, loss = 1.82306131\n",
      "Iteration 6, loss = 1.83244531\n",
      "Iteration 6, loss = 1.80530857\n",
      "Iteration 88, loss = 1.36451307\n",
      "Iteration 15, loss = 1.41369377\n",
      "Iteration 7, loss = 1.82470885\n",
      "Iteration 89, loss = 1.36453626\n",
      "Iteration 7, loss = 1.79459193\n",
      "Iteration 16, loss = 1.41190249\n",
      "Iteration 90, loss = 1.36316555\n",
      "Iteration 8, loss = 1.81524912\n",
      "Iteration 17, loss = 1.40836799\n",
      "Iteration 8, loss = 1.78495338\n",
      "Iteration 91, loss = 1.36297926\n",
      "Iteration 9, loss = 1.80854971\n",
      "Iteration 18, loss = 1.40416267\n",
      "Iteration 9, loss = 1.77590847\n",
      "Iteration 92, loss = 1.36356772\n",
      "Iteration 10, loss = 1.80351065\n",
      "Iteration 19, loss = 1.40203155\n",
      "Iteration 10, loss = 1.76911987\n",
      "Iteration 93, loss = 1.36260681\n",
      "Iteration 11, loss = 1.79703270\n",
      "Iteration 11, loss = 1.76414358\n",
      "Iteration 20, loss = 1.39928872\n",
      "Iteration 94, loss = 1.36306852\n",
      "Iteration 12, loss = 1.79143523\n",
      "Iteration 12, loss = 1.75789637\n",
      "Iteration 21, loss = 1.39700660\n",
      "Iteration 95, loss = 1.36191779\n",
      "Iteration 13, loss = 1.78893731\n",
      "Iteration 13, loss = 1.75286854\n",
      "Iteration 22, loss = 1.39526925\n",
      "Iteration 96, loss = 1.36311867\n",
      "Iteration 14, loss = 1.78433098\n",
      "Iteration 14, loss = 1.75019326\n",
      "Iteration 23, loss = 1.39203545\n",
      "Iteration 15, loss = 1.78143842\n",
      "Iteration 97, loss = 1.36194249\n",
      "Iteration 15, loss = 1.74817860\n",
      "Iteration 24, loss = 1.38964481\n",
      "Iteration 16, loss = 1.77825687\n",
      "Iteration 98, loss = 1.36227766\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 16, loss = 1.74397800\n",
      "Iteration 17, loss = 1.77535314\n",
      "Iteration 1, loss = 4.75318562\n",
      "Iteration 25, loss = 1.38758820\n",
      "Iteration 17, loss = 1.74130028\n",
      "Iteration 2, loss = 2.39362322\n",
      "Iteration 18, loss = 1.77227915\n",
      "Iteration 26, loss = 1.38689095\n",
      "Iteration 18, loss = 1.73799961\n",
      "Iteration 3, loss = 1.94649881\n",
      "Iteration 19, loss = 1.77146407\n",
      "Iteration 19, loss = 1.73628052\n",
      "Iteration 27, loss = 1.38457793\n",
      "Iteration 4, loss = 1.84780909\n",
      "Iteration 20, loss = 1.76796908\n",
      "Iteration 20, loss = 1.73406619\n",
      "Iteration 5, loss = 1.81539620\n",
      "Iteration 28, loss = 1.38308843\n",
      "Iteration 21, loss = 1.76646442\n",
      "Iteration 21, loss = 1.73206405\n",
      "Iteration 6, loss = 1.80102139\n",
      "Iteration 29, loss = 1.38185153\n",
      "Iteration 22, loss = 1.76395740\n",
      "Iteration 22, loss = 1.72963190\n",
      "Iteration 7, loss = 1.78851441\n",
      "Iteration 30, loss = 1.38044620\n",
      "Iteration 23, loss = 1.76312523\n",
      "Iteration 23, loss = 1.72826279\n",
      "Iteration 8, loss = 1.77943806\n",
      "Iteration 31, loss = 1.37923477\n",
      "Iteration 24, loss = 1.76143268\n",
      "Iteration 24, loss = 1.72714006\n",
      "Iteration 32, loss = 1.37821521\n",
      "Iteration 9, loss = 1.77275109\n",
      "Iteration 25, loss = 1.76010651\n",
      "Iteration 25, loss = 1.72487489\n",
      "Iteration 26, loss = 1.75832045\n",
      "Iteration 33, loss = 1.37677387\n",
      "Iteration 10, loss = 1.76588031\n",
      "Iteration 26, loss = 1.72538221\n",
      "Iteration 27, loss = 1.75842289\n",
      "Iteration 11, loss = 1.76025698\n",
      "Iteration 34, loss = 1.37505390\n",
      "Iteration 27, loss = 1.72316247\n",
      "Iteration 28, loss = 1.75728708\n",
      "Iteration 12, loss = 1.75615715\n",
      "Iteration 35, loss = 1.37461309\n",
      "Iteration 28, loss = 1.72129695\n",
      "Iteration 29, loss = 1.75563614\n",
      "Iteration 13, loss = 1.75083740\n",
      "Iteration 36, loss = 1.37261069\n",
      "Iteration 29, loss = 1.72177351\n",
      "Iteration 30, loss = 1.75458543\n",
      "Iteration 14, loss = 1.74838343\n",
      "Iteration 30, loss = 1.72064942\n",
      "Iteration 37, loss = 1.37242138\n",
      "Iteration 31, loss = 1.75432761\n",
      "Iteration 15, loss = 1.74383105\n",
      "Iteration 31, loss = 1.71793855\n",
      "Iteration 38, loss = 1.37227439\n",
      "Iteration 32, loss = 1.75346840\n",
      "Iteration 16, loss = 1.74186784\n",
      "Iteration 32, loss = 1.71755625\n",
      "Iteration 39, loss = 1.37053287\n",
      "Iteration 33, loss = 1.75244990\n",
      "Iteration 17, loss = 1.73874612\n",
      "Iteration 33, loss = 1.71706968\n",
      "Iteration 40, loss = 1.36927901\n",
      "Iteration 34, loss = 1.75165579\n",
      "Iteration 18, loss = 1.73566017\n",
      "Iteration 34, loss = 1.71656276\n",
      "Iteration 41, loss = 1.36873723\n",
      "Iteration 35, loss = 1.75044060\n",
      "Iteration 19, loss = 1.73426041\n",
      "Iteration 35, loss = 1.71507101\n",
      "Iteration 42, loss = 1.36837720\n",
      "Iteration 36, loss = 1.74952581\n",
      "Iteration 20, loss = 1.73137732\n",
      "Iteration 36, loss = 1.71445877\n",
      "Iteration 37, loss = 1.74909850\n",
      "Iteration 43, loss = 1.36788062\n",
      "Iteration 37, loss = 1.71387102\n",
      "Iteration 21, loss = 1.72918182\n",
      "Iteration 38, loss = 1.74962816\n",
      "Iteration 44, loss = 1.36686837\n",
      "Iteration 38, loss = 1.71375982\n",
      "Iteration 22, loss = 1.72753084\n",
      "Iteration 39, loss = 1.74807359\n",
      "Iteration 45, loss = 1.36611202\n",
      "Iteration 39, loss = 1.71331899\n",
      "Iteration 23, loss = 1.72723717\n",
      "Iteration 40, loss = 1.74825145\n",
      "Iteration 46, loss = 1.36575983\n",
      "Iteration 40, loss = 1.71243213\n",
      "Iteration 24, loss = 1.72437275\n",
      "Iteration 41, loss = 1.74768106\n",
      "Iteration 47, loss = 1.36441932\n",
      "Iteration 41, loss = 1.71222799\n",
      "Iteration 25, loss = 1.72303898\n",
      "Iteration 42, loss = 1.74675309\n",
      "Iteration 42, loss = 1.71079938\n",
      "Iteration 48, loss = 1.36375999\n",
      "Iteration 26, loss = 1.72300367\n",
      "Iteration 43, loss = 1.74630650\n",
      "Iteration 43, loss = 1.71069684\n",
      "Iteration 27, loss = 1.72127378\n",
      "Iteration 49, loss = 1.36387178\n",
      "Iteration 44, loss = 1.74635145\n",
      "Iteration 44, loss = 1.71088388\n",
      "Iteration 28, loss = 1.71922631\n",
      "Iteration 50, loss = 1.36307422\n",
      "Iteration 45, loss = 1.74535881\n",
      "Iteration 45, loss = 1.70949743\n",
      "Iteration 29, loss = 1.71725908\n",
      "Iteration 51, loss = 1.36206218\n",
      "Iteration 46, loss = 1.74522164\n",
      "Iteration 46, loss = 1.70913280\n",
      "Iteration 30, loss = 1.71715282\n",
      "Iteration 47, loss = 1.74462327\n",
      "Iteration 52, loss = 1.36111186\n",
      "Iteration 47, loss = 1.70833399\n",
      "Iteration 31, loss = 1.71703787\n",
      "Iteration 48, loss = 1.74444899\n",
      "Iteration 53, loss = 1.36106916\n",
      "Iteration 48, loss = 1.70844520\n",
      "Iteration 32, loss = 1.71540031\n",
      "Iteration 49, loss = 1.74310745\n",
      "Iteration 54, loss = 1.36066258\n",
      "Iteration 49, loss = 1.70779784\n",
      "Iteration 33, loss = 1.71472033\n",
      "Iteration 50, loss = 1.74368630\n",
      "Iteration 55, loss = 1.36017513\n",
      "Iteration 50, loss = 1.70783772\n",
      "Iteration 34, loss = 1.71439337\n",
      "Iteration 51, loss = 1.74400173\n",
      "Iteration 56, loss = 1.35988831\n",
      "Iteration 51, loss = 1.70722584\n",
      "Iteration 35, loss = 1.71270589\n",
      "Iteration 52, loss = 1.74226622\n",
      "Iteration 52, loss = 1.70705529\n",
      "Iteration 57, loss = 1.35831229\n",
      "Iteration 36, loss = 1.71212846\n",
      "Iteration 53, loss = 1.74325832\n",
      "Iteration 53, loss = 1.70648304\n",
      "Iteration 58, loss = 1.35827323\n",
      "Iteration 37, loss = 1.71184710\n",
      "Iteration 54, loss = 1.74228772\n",
      "Iteration 54, loss = 1.70680063\n",
      "Iteration 38, loss = 1.71209425\n",
      "Iteration 59, loss = 1.35775310\n",
      "Iteration 55, loss = 1.74235026\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 55, loss = 1.70589086\n",
      "Iteration 39, loss = 1.71099403\n",
      "Iteration 1, loss = 4.71530376\n",
      "Iteration 60, loss = 1.35768222\n",
      "Iteration 56, loss = 1.70535085\n",
      "Iteration 2, loss = 2.40473548\n",
      "Iteration 40, loss = 1.71140722\n",
      "Iteration 61, loss = 1.35725782\n",
      "Iteration 3, loss = 1.96558926\n",
      "Iteration 57, loss = 1.70521482\n",
      "Iteration 41, loss = 1.71057775\n",
      "Iteration 62, loss = 1.35641823\n",
      "Iteration 4, loss = 1.87738421\n",
      "Iteration 58, loss = 1.70458871\n",
      "Iteration 42, loss = 1.70935590\n",
      "Iteration 63, loss = 1.35601209\n",
      "Iteration 5, loss = 1.84571407\n",
      "Iteration 59, loss = 1.70576396\n",
      "Iteration 43, loss = 1.70888854\n",
      "Iteration 6, loss = 1.82983658\n",
      "Iteration 64, loss = 1.35741241\n",
      "Iteration 60, loss = 1.70480610\n",
      "Iteration 44, loss = 1.70850169\n",
      "Iteration 65, loss = 1.35587144\n",
      "Iteration 7, loss = 1.82029828\n",
      "Iteration 61, loss = 1.70323452\n",
      "Iteration 45, loss = 1.70829744\n",
      "Iteration 66, loss = 1.35570112\n",
      "Iteration 62, loss = 1.70434775\n",
      "Iteration 8, loss = 1.81202977\n",
      "Iteration 46, loss = 1.70800788\n",
      "Iteration 63, loss = 1.70358499\n",
      "Iteration 67, loss = 1.35528726\n",
      "Iteration 47, loss = 1.70797342\n",
      "Iteration 9, loss = 1.80606792\n",
      "Iteration 64, loss = 1.70334992\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 68, loss = 1.35484438\n",
      "Iteration 48, loss = 1.70707604\n",
      "Iteration 10, loss = 1.80009458\n",
      "Iteration 1, loss = 4.75496232\n",
      "Iteration 69, loss = 1.35422556\n",
      "Iteration 49, loss = 1.70660310\n",
      "Iteration 11, loss = 1.79619934\n",
      "Iteration 2, loss = 2.40392651\n",
      "Iteration 50, loss = 1.70550185\n",
      "Iteration 70, loss = 1.35438350\n",
      "Iteration 12, loss = 1.79187603\n",
      "Iteration 3, loss = 1.95834338\n",
      "Iteration 51, loss = 1.70573349\n",
      "Iteration 71, loss = 1.35359430\n",
      "Iteration 13, loss = 1.78645544\n",
      "Iteration 4, loss = 1.85760069\n",
      "Iteration 52, loss = 1.70514047\n",
      "Iteration 5, loss = 1.82352758\n",
      "Iteration 72, loss = 1.35279677\n",
      "Iteration 14, loss = 1.78474586\n",
      "Iteration 53, loss = 1.70447074\n",
      "Iteration 6, loss = 1.81023980\n",
      "Iteration 73, loss = 1.35406282\n",
      "Iteration 15, loss = 1.78116951\n",
      "Iteration 54, loss = 1.70428742\n",
      "Iteration 7, loss = 1.79827489\n",
      "Iteration 16, loss = 1.77678121\n",
      "Iteration 74, loss = 1.35317765\n",
      "Iteration 55, loss = 1.70336664\n",
      "Iteration 17, loss = 1.77488727\n",
      "Iteration 75, loss = 1.35309207\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 8, loss = 1.78927059\n",
      "Iteration 56, loss = 1.70393379\n",
      "Iteration 18, loss = 1.77190284\n",
      "Iteration 1, loss = 6.93985894\n",
      "Iteration 9, loss = 1.78160343\n",
      "Iteration 57, loss = 1.70228487\n",
      "Iteration 2, loss = 2.66199975\n",
      "Iteration 19, loss = 1.77072972\n",
      "Iteration 10, loss = 1.77548525\n",
      "Iteration 58, loss = 1.70277283\n",
      "Iteration 3, loss = 2.32444930\n",
      "Iteration 20, loss = 1.76803717\n",
      "Iteration 11, loss = 1.76861565\n",
      "Iteration 59, loss = 1.70196316\n",
      "Iteration 4, loss = 2.28909447\n",
      "Iteration 21, loss = 1.76499682\n",
      "Iteration 12, loss = 1.76306304\n",
      "Iteration 60, loss = 1.70299517\n",
      "Iteration 5, loss = 2.25592083\n",
      "Iteration 22, loss = 1.76460822\n",
      "Iteration 6, loss = 2.23293851\n",
      "Iteration 61, loss = 1.70171888\n",
      "Iteration 13, loss = 1.75902628\n",
      "Iteration 23, loss = 1.76278258\n",
      "Iteration 62, loss = 1.70170744\n",
      "Iteration 14, loss = 1.75404847\n",
      "Iteration 7, loss = 2.21761131\n",
      "Iteration 24, loss = 1.76073343\n",
      "Iteration 63, loss = 1.70187645\n",
      "Iteration 15, loss = 1.75079552\n",
      "Iteration 8, loss = 2.20659045\n",
      "Iteration 25, loss = 1.75990623\n",
      "Iteration 64, loss = 1.70116425\n",
      "Iteration 9, loss = 2.19918054\n",
      "Iteration 16, loss = 1.74881645\n",
      "Iteration 26, loss = 1.75821900\n",
      "Iteration 65, loss = 1.70084546\n",
      "Iteration 10, loss = 2.19402075\n",
      "Iteration 17, loss = 1.74538011\n",
      "Iteration 27, loss = 1.75648375\n",
      "Iteration 66, loss = 1.70047812\n",
      "Iteration 11, loss = 2.18944783\n",
      "Iteration 18, loss = 1.74290812\n",
      "Iteration 28, loss = 1.75503002\n",
      "Iteration 67, loss = 1.70061128\n",
      "Iteration 12, loss = 2.18499069\n",
      "Iteration 19, loss = 1.74045977\n",
      "Iteration 29, loss = 1.75479204\n",
      "Iteration 13, loss = 2.18248385\n",
      "Iteration 68, loss = 1.70093181\n",
      "Iteration 20, loss = 1.73759202\n",
      "Iteration 30, loss = 1.75395468\n",
      "Iteration 14, loss = 2.17974330\n",
      "Iteration 69, loss = 1.69995146\n",
      "Iteration 21, loss = 1.73633432\n",
      "Iteration 31, loss = 1.75268765\n",
      "Iteration 15, loss = 2.17786878\n",
      "Iteration 70, loss = 1.70006580\n",
      "Iteration 22, loss = 1.73480296\n",
      "Iteration 32, loss = 1.75167669\n",
      "Iteration 16, loss = 2.17485601\n",
      "Iteration 71, loss = 1.70088490\n",
      "Iteration 23, loss = 1.73097963\n",
      "Iteration 33, loss = 1.75116554\n",
      "Iteration 17, loss = 2.17354576\n",
      "Iteration 72, loss = 1.69959603\n",
      "Iteration 24, loss = 1.73055590\n",
      "Iteration 34, loss = 1.75015296\n",
      "Iteration 18, loss = 2.17230432\n",
      "Iteration 73, loss = 1.70004156\n",
      "Iteration 25, loss = 1.72838947\n",
      "Iteration 19, loss = 2.17126153\n",
      "Iteration 35, loss = 1.74917191\n",
      "Iteration 74, loss = 1.69997901\n",
      "Iteration 26, loss = 1.72745673\n",
      "Iteration 20, loss = 2.16971762\n",
      "Iteration 36, loss = 1.74789352\n",
      "Iteration 75, loss = 1.69943761\n",
      "Iteration 27, loss = 1.72583564\n",
      "Iteration 21, loss = 2.16835554\n",
      "Iteration 37, loss = 1.74786458\n",
      "Iteration 76, loss = 1.69916756\n",
      "Iteration 28, loss = 1.72417927\n",
      "Iteration 22, loss = 2.16726674\n",
      "Iteration 38, loss = 1.74602375\n",
      "Iteration 77, loss = 1.69909892\n",
      "Iteration 23, loss = 2.16693080\n",
      "Iteration 29, loss = 1.72351290\n",
      "Iteration 39, loss = 1.74541882\n",
      "Iteration 78, loss = 1.69936162\n",
      "Iteration 24, loss = 2.16552194\n",
      "Iteration 30, loss = 1.72264952\n",
      "Iteration 40, loss = 1.74550233\n",
      "Iteration 79, loss = 1.69942458\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 25, loss = 2.16514747\n",
      "Iteration 31, loss = 1.72098725\n",
      "Iteration 41, loss = 1.74479286\n",
      "Iteration 1, loss = 6.97515782\n",
      "Iteration 26, loss = 2.16351713\n",
      "Iteration 32, loss = 1.72161150\n",
      "Iteration 42, loss = 1.74379298\n",
      "Iteration 2, loss = 2.64751106\n",
      "Iteration 27, loss = 2.16354279\n",
      "Iteration 33, loss = 1.71942181\n",
      "Iteration 43, loss = 1.74300876\n",
      "Iteration 3, loss = 2.29595229\n",
      "Iteration 28, loss = 2.16330900\n",
      "Iteration 34, loss = 1.71937270\n",
      "Iteration 44, loss = 1.74222448\n",
      "Iteration 4, loss = 2.25309627\n",
      "Iteration 29, loss = 2.16277594\n",
      "Iteration 35, loss = 1.71781818\n",
      "Iteration 5, loss = 2.21517901\n",
      "Iteration 45, loss = 1.74280426\n",
      "Iteration 30, loss = 2.16225335\n",
      "Iteration 36, loss = 1.71673958\n",
      "Iteration 6, loss = 2.19318503\n",
      "Iteration 31, loss = 2.16236127\n",
      "Iteration 46, loss = 1.74073257\n",
      "Iteration 37, loss = 1.71651946\n",
      "Iteration 32, loss = 2.16113961\n",
      "Iteration 47, loss = 1.74098164\n",
      "Iteration 7, loss = 2.17975291\n",
      "Iteration 38, loss = 1.71613784\n",
      "Iteration 33, loss = 2.16113215\n",
      "Iteration 48, loss = 1.73938754\n",
      "Iteration 8, loss = 2.16682977\n",
      "Iteration 39, loss = 1.71427031\n",
      "Iteration 34, loss = 2.16046323\n",
      "Iteration 49, loss = 1.73935414\n",
      "Iteration 9, loss = 2.15742932\n",
      "Iteration 40, loss = 1.71368975\n",
      "Iteration 35, loss = 2.15960807\n",
      "Iteration 50, loss = 1.74035300\n",
      "Iteration 10, loss = 2.15171679\n",
      "Iteration 41, loss = 1.71386256\n",
      "Iteration 36, loss = 2.15974066\n",
      "Iteration 51, loss = 1.73860083\n",
      "Iteration 11, loss = 2.14581729\n",
      "Iteration 42, loss = 1.71334265\n",
      "Iteration 37, loss = 2.15972589\n",
      "Iteration 52, loss = 1.73868853\n",
      "Iteration 12, loss = 2.14238452\n",
      "Iteration 43, loss = 1.71291822\n",
      "Iteration 38, loss = 2.15935223\n",
      "Iteration 53, loss = 1.73814208\n",
      "Iteration 13, loss = 2.13835220\n",
      "Iteration 39, loss = 2.15895098\n",
      "Iteration 44, loss = 1.71213413\n",
      "Iteration 54, loss = 1.73753244\n",
      "Iteration 14, loss = 2.13519203\n",
      "Iteration 40, loss = 2.15882300\n",
      "Iteration 45, loss = 1.71078591\n",
      "Iteration 55, loss = 1.73787185\n",
      "Iteration 15, loss = 2.13364241\n",
      "Iteration 41, loss = 2.15897072\n",
      "Iteration 46, loss = 1.71099408\n",
      "Iteration 56, loss = 1.73670142\n",
      "Iteration 16, loss = 2.13066588\n",
      "Iteration 42, loss = 2.15824677\n",
      "Iteration 47, loss = 1.70997586\n",
      "Iteration 57, loss = 1.73678899\n",
      "Iteration 17, loss = 2.12886694\n",
      "Iteration 43, loss = 2.15811510\n",
      "Iteration 48, loss = 1.70968882\n",
      "Iteration 18, loss = 2.12683804\n",
      "Iteration 58, loss = 1.73683546\n",
      "Iteration 44, loss = 2.15839797\n",
      "Iteration 49, loss = 1.70957042\n",
      "Iteration 19, loss = 2.12505435\n",
      "Iteration 59, loss = 1.73737860\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 45, loss = 2.15737882\n",
      "Iteration 50, loss = 1.70977421\n",
      "Iteration 20, loss = 2.12402377\n",
      "Iteration 1, loss = 6.93314649\n",
      "Iteration 46, loss = 2.15758775\n",
      "Iteration 51, loss = 1.70777112\n",
      "Iteration 21, loss = 2.12270173\n",
      "Iteration 2, loss = 2.63402611\n",
      "Iteration 47, loss = 2.15709632\n",
      "Iteration 52, loss = 1.70830473\n",
      "Iteration 3, loss = 2.29177683\n",
      "Iteration 22, loss = 2.12156486\n",
      "Iteration 48, loss = 2.15726945\n",
      "Iteration 53, loss = 1.70769602\n",
      "Iteration 4, loss = 2.25097684\n",
      "Iteration 23, loss = 2.12080700\n",
      "Iteration 49, loss = 2.15684684\n",
      "Iteration 5, loss = 2.22185333\n",
      "Iteration 54, loss = 1.70785795\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 24, loss = 2.11958468\n",
      "Iteration 50, loss = 2.15655945\n",
      "Iteration 6, loss = 2.19535802\n",
      "Iteration 25, loss = 2.11874205\n",
      "Iteration 1, loss = 6.88360436\n",
      "Iteration 51, loss = 2.15712480\n",
      "Iteration 26, loss = 2.11844327\n",
      "Iteration 2, loss = 2.64397610\n",
      "Iteration 7, loss = 2.17835800\n",
      "Iteration 52, loss = 2.15599123\n",
      "Iteration 3, loss = 2.31216211\n",
      "Iteration 27, loss = 2.11785280\n",
      "Iteration 53, loss = 2.15565332\n",
      "Iteration 8, loss = 2.16800132\n",
      "Iteration 4, loss = 2.27238284\n",
      "Iteration 28, loss = 2.11673811\n",
      "Iteration 54, loss = 2.15612988\n",
      "Iteration 9, loss = 2.16047455\n",
      "Iteration 5, loss = 2.23488964\n",
      "Iteration 29, loss = 2.11628182\n",
      "Iteration 55, loss = 2.15627215\n",
      "Iteration 10, loss = 2.15578882\n",
      "Iteration 6, loss = 2.21302429\n",
      "Iteration 30, loss = 2.11664498\n",
      "Iteration 56, loss = 2.15628097\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 11, loss = 2.15053342\n",
      "Iteration 31, loss = 2.11487538\n",
      "Iteration 7, loss = 2.19803935\n",
      "Iteration 1, loss = 6.91062338\n",
      "Iteration 12, loss = 2.14670828\n",
      "Iteration 32, loss = 2.11494994\n",
      "Iteration 2, loss = 2.60928470\n",
      "Iteration 8, loss = 2.18756136\n",
      "Iteration 13, loss = 2.14310017\n",
      "Iteration 33, loss = 2.11465448\n",
      "Iteration 3, loss = 2.28195828\n",
      "Iteration 9, loss = 2.18032497\n",
      "Iteration 14, loss = 2.14055003\n",
      "Iteration 34, loss = 2.11484340\n",
      "Iteration 4, loss = 2.22576764\n",
      "Iteration 10, loss = 2.17451066\n",
      "Iteration 15, loss = 2.13798869\n",
      "Iteration 35, loss = 2.11386539\n",
      "Iteration 5, loss = 2.19811179\n",
      "Iteration 11, loss = 2.16943293\n",
      "Iteration 16, loss = 2.13670701\n",
      "Iteration 36, loss = 2.11295120\n",
      "Iteration 6, loss = 2.17975185\n",
      "Iteration 12, loss = 2.16562678\n",
      "Iteration 17, loss = 2.13441038\n",
      "Iteration 37, loss = 2.11350818\n",
      "Iteration 13, loss = 2.16121343\n",
      "Iteration 7, loss = 2.16558281\n",
      "Iteration 18, loss = 2.13207835\n",
      "Iteration 38, loss = 2.11296216\n",
      "Iteration 14, loss = 2.15995147\n",
      "Iteration 19, loss = 2.13155542\n",
      "Iteration 8, loss = 2.15539705\n",
      "Iteration 39, loss = 2.11229543\n",
      "Iteration 15, loss = 2.15733359\n",
      "Iteration 20, loss = 2.12898591\n",
      "Iteration 9, loss = 2.14663684\n",
      "Iteration 40, loss = 2.11206767\n",
      "Iteration 16, loss = 2.15493118\n",
      "Iteration 21, loss = 2.12862916\n",
      "Iteration 10, loss = 2.14144589\n",
      "Iteration 41, loss = 2.11200494\n",
      "Iteration 17, loss = 2.15328952\n",
      "Iteration 22, loss = 2.12636725\n",
      "Iteration 11, loss = 2.13518107\n",
      "Iteration 42, loss = 2.11143536\n",
      "Iteration 18, loss = 2.15137024\n",
      "Iteration 23, loss = 2.12657145\n",
      "Iteration 12, loss = 2.13164561\n",
      "Iteration 43, loss = 2.11118385\n",
      "Iteration 19, loss = 2.15071623\n",
      "Iteration 24, loss = 2.12530615\n",
      "Iteration 44, loss = 2.11200584\n",
      "Iteration 13, loss = 2.12769811\n",
      "Iteration 20, loss = 2.14859827\n",
      "Iteration 25, loss = 2.12406977\n",
      "Iteration 45, loss = 2.11051370\n",
      "Iteration 14, loss = 2.12451243\n",
      "Iteration 21, loss = 2.14671749\n",
      "Iteration 26, loss = 2.12439200\n",
      "Iteration 46, loss = 2.11032110\n",
      "Iteration 15, loss = 2.12211873\n",
      "Iteration 22, loss = 2.14762276\n",
      "Iteration 27, loss = 2.12276735\n",
      "Iteration 47, loss = 2.10995710\n",
      "Iteration 16, loss = 2.11992473\n",
      "Iteration 23, loss = 2.14601187\n",
      "Iteration 28, loss = 2.12238935\n",
      "Iteration 48, loss = 2.10922042\n",
      "Iteration 17, loss = 2.11804449\n",
      "Iteration 24, loss = 2.14488504\n",
      "Iteration 29, loss = 2.12082232\n",
      "Iteration 49, loss = 2.10983213\n",
      "Iteration 18, loss = 2.11619349\n",
      "Iteration 30, loss = 2.12036984\n",
      "Iteration 25, loss = 2.14409231\n",
      "Iteration 50, loss = 2.10918712\n",
      "Iteration 19, loss = 2.11539459\n",
      "Iteration 31, loss = 2.12003724\n",
      "Iteration 26, loss = 2.14344016\n",
      "Iteration 51, loss = 2.10976475\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 20, loss = 2.11322516\n",
      "Iteration 32, loss = 2.11882129\n",
      "Iteration 27, loss = 2.14251298\n",
      "Iteration 1, loss = 9.80051369\n",
      "Iteration 21, loss = 2.11227964\n",
      "Iteration 33, loss = 2.11888685\n",
      "Iteration 28, loss = 2.14186450\n",
      "Iteration 2, loss = 2.74623351\n",
      "Iteration 22, loss = 2.11101196\n",
      "Iteration 34, loss = 2.11895862\n",
      "Iteration 29, loss = 2.14161729\n",
      "Iteration 3, loss = 2.55942137\n",
      "Iteration 23, loss = 2.10893127\n",
      "Iteration 35, loss = 2.11789078\n",
      "Iteration 30, loss = 2.14115504\n",
      "Iteration 4, loss = 2.54173594\n",
      "Iteration 24, loss = 2.10878881\n",
      "Iteration 36, loss = 2.11747959\n",
      "Iteration 31, loss = 2.13982285\n",
      "Iteration 5, loss = 2.53073223\n",
      "Iteration 25, loss = 2.10772670\n",
      "Iteration 37, loss = 2.11769237\n",
      "Iteration 32, loss = 2.13980179\n",
      "Iteration 6, loss = 2.52482490\n",
      "Iteration 26, loss = 2.10735035\n",
      "Iteration 38, loss = 2.11703853\n",
      "Iteration 33, loss = 2.13933416\n",
      "Iteration 7, loss = 2.51910152\n",
      "Iteration 27, loss = 2.10584673\n",
      "Iteration 39, loss = 2.11694350\n",
      "Iteration 34, loss = 2.13882883\n",
      "Iteration 8, loss = 2.51671895\n",
      "Iteration 28, loss = 2.10541037\n",
      "Iteration 40, loss = 2.11690142\n",
      "Iteration 35, loss = 2.13840691\n",
      "Iteration 9, loss = 2.51428265\n",
      "Iteration 29, loss = 2.10529434\n",
      "Iteration 41, loss = 2.11628608\n",
      "Iteration 36, loss = 2.13761564\n",
      "Iteration 10, loss = 2.51231260\n",
      "Iteration 30, loss = 2.10525600\n",
      "Iteration 42, loss = 2.11582202\n",
      "Iteration 37, loss = 2.13895203\n",
      "Iteration 11, loss = 2.51127800\n",
      "Iteration 31, loss = 2.10339199\n",
      "Iteration 43, loss = 2.11541302\n",
      "Iteration 38, loss = 2.13771747\n",
      "Iteration 12, loss = 2.50991098\n",
      "Iteration 32, loss = 2.10453661\n",
      "Iteration 44, loss = 2.11490093\n",
      "Iteration 39, loss = 2.13721917\n",
      "Iteration 13, loss = 2.50863501\n",
      "Iteration 33, loss = 2.10325535\n",
      "Iteration 45, loss = 2.11560525\n",
      "Iteration 40, loss = 2.13773576\n",
      "Iteration 14, loss = 2.50801952\n",
      "Iteration 34, loss = 2.10344392\n",
      "Iteration 46, loss = 2.11416408\n",
      "Iteration 41, loss = 2.13756627\n",
      "Iteration 15, loss = 2.50773051\n",
      "Iteration 35, loss = 2.10241414\n",
      "Iteration 47, loss = 2.11411193\n",
      "Iteration 42, loss = 2.13622376\n",
      "Iteration 16, loss = 2.50642481\n",
      "Iteration 36, loss = 2.10157332\n",
      "Iteration 48, loss = 2.11445144\n",
      "Iteration 43, loss = 2.13601104\n",
      "Iteration 17, loss = 2.50590936\n",
      "Iteration 37, loss = 2.10223087\n",
      "Iteration 49, loss = 2.11389346\n",
      "Iteration 44, loss = 2.13603024\n",
      "Iteration 18, loss = 2.50589357\n",
      "Iteration 38, loss = 2.10138413\n",
      "Iteration 50, loss = 2.11282331\n",
      "Iteration 19, loss = 2.50558961\n",
      "Iteration 45, loss = 2.13586543\n",
      "Iteration 39, loss = 2.10048067\n",
      "Iteration 51, loss = 2.11337467\n",
      "Iteration 20, loss = 2.50505576\n",
      "Iteration 46, loss = 2.13469005\n",
      "Iteration 40, loss = 2.09976229\n",
      "Iteration 52, loss = 2.11290116\n",
      "Iteration 21, loss = 2.50449233\n",
      "Iteration 47, loss = 2.13571744\n",
      "Iteration 41, loss = 2.09996994\n",
      "Iteration 53, loss = 2.11313589\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 22, loss = 2.50426566\n",
      "Iteration 48, loss = 2.13448096\n",
      "Iteration 42, loss = 2.09987795\n",
      "Iteration 1, loss = 9.83730368\n",
      "Iteration 23, loss = 2.50362903\n",
      "Iteration 49, loss = 2.13507906\n",
      "Iteration 43, loss = 2.09911279\n",
      "Iteration 2, loss = 2.73171387\n",
      "Iteration 24, loss = 2.50380655\n",
      "Iteration 50, loss = 2.13580248\n",
      "Iteration 44, loss = 2.09912980\n",
      "Iteration 3, loss = 2.52852362\n",
      "Iteration 25, loss = 2.50359609\n",
      "Iteration 51, loss = 2.13424197\n",
      "Iteration 45, loss = 2.09869746\n",
      "Iteration 4, loss = 2.50110030\n",
      "Iteration 26, loss = 2.50293238\n",
      "Iteration 52, loss = 2.13441056\n",
      "Iteration 46, loss = 2.09842920\n",
      "Iteration 5, loss = 2.48678941\n",
      "Iteration 27, loss = 2.50348300\n",
      "Iteration 53, loss = 2.13433025\n",
      "Iteration 6, loss = 2.47755979\n",
      "Iteration 47, loss = 2.09802914\n",
      "Iteration 28, loss = 2.50331340\n",
      "Iteration 54, loss = 2.13426222\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 29, loss = 2.50344134\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 48, loss = 2.09789205\n",
      "Iteration 7, loss = 2.47243479\n",
      "Iteration 1, loss = 9.76016823\n",
      "Iteration 1, loss = 9.65460845\n",
      "Iteration 49, loss = 2.09805257\n",
      "Iteration 8, loss = 2.46855264\n",
      "Iteration 2, loss = 2.73490927\n",
      "Iteration 2, loss = 2.73105036\n",
      "Iteration 50, loss = 2.09798931\n",
      "Iteration 3, loss = 2.54415784\n",
      "Iteration 9, loss = 2.46520184\n",
      "Iteration 3, loss = 2.55456678\n",
      "Iteration 51, loss = 2.09681797\n",
      "Iteration 4, loss = 2.52132406\n",
      "Iteration 10, loss = 2.46436663\n",
      "Iteration 4, loss = 2.53473245\n",
      "Iteration 52, loss = 2.09724890\n",
      "Iteration 5, loss = 2.51079588\n",
      "Iteration 11, loss = 2.46220219\n",
      "Iteration 5, loss = 2.52316869\n",
      "Iteration 53, loss = 2.09666371\n",
      "Iteration 6, loss = 2.50220959\n",
      "Iteration 12, loss = 2.46095873\n",
      "Iteration 6, loss = 2.51662741\n",
      "Iteration 54, loss = 2.09712338\n",
      "Iteration 13, loss = 2.45862364\n",
      "Iteration 7, loss = 2.49754903\n",
      "Iteration 55, loss = 2.09678330\n",
      "Iteration 7, loss = 2.51197331\n",
      "Iteration 14, loss = 2.45763849\n",
      "Iteration 8, loss = 2.49389825\n",
      "Iteration 56, loss = 2.09735383\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 8, loss = 2.50856207\n",
      "Iteration 15, loss = 2.45750359\n",
      "Iteration 9, loss = 2.49125327\n",
      "Iteration 1, loss = 9.67066145\n",
      "Iteration 9, loss = 2.50570263\n",
      "Iteration 16, loss = 2.45682259\n",
      "Iteration 10, loss = 2.48967981\n",
      "Iteration 2, loss = 2.71338423\n",
      "Iteration 10, loss = 2.50394348\n",
      "Iteration 17, loss = 2.45644098\n",
      "Iteration 11, loss = 2.48734021\n",
      "Iteration 3, loss = 2.53388008\n",
      "Iteration 11, loss = 2.50189767\n",
      "Iteration 18, loss = 2.45554314\n",
      "Iteration 12, loss = 2.48584243\n",
      "Iteration 4, loss = 2.50980257\n",
      "Iteration 12, loss = 2.50072574\n",
      "Iteration 19, loss = 2.45483268\n",
      "Iteration 13, loss = 2.48491722\n",
      "Iteration 5, loss = 2.49642229\n",
      "Iteration 13, loss = 2.49974432\n",
      "Iteration 20, loss = 2.45463791\n",
      "Iteration 14, loss = 2.48424801\n",
      "Iteration 6, loss = 2.48855483\n",
      "Iteration 14, loss = 2.49865967\n",
      "Iteration 21, loss = 2.45416726\n",
      "Iteration 15, loss = 2.48287277\n",
      "Iteration 15, loss = 2.49782906\n",
      "Iteration 22, loss = 2.45355938\n",
      "Iteration 7, loss = 2.48323883\n",
      "Iteration 16, loss = 2.48257062\n",
      "Iteration 16, loss = 2.49724465\n",
      "Iteration 23, loss = 2.45368927\n",
      "Iteration 8, loss = 2.48013208\n",
      "Iteration 17, loss = 2.48158580\n",
      "Iteration 17, loss = 2.49673470\n",
      "Iteration 24, loss = 2.45347403\n",
      "Iteration 9, loss = 2.47674379\n",
      "Iteration 18, loss = 2.48107845\n",
      "Iteration 18, loss = 2.49624778\n",
      "Iteration 25, loss = 2.45296845\n",
      "Iteration 10, loss = 2.47461217\n",
      "Iteration 19, loss = 2.48125274\n",
      "Iteration 19, loss = 2.49529239\n",
      "Iteration 26, loss = 2.45232072\n",
      "Iteration 11, loss = 2.47273655\n",
      "Iteration 20, loss = 2.48005825\n",
      "Iteration 20, loss = 2.49502923\n",
      "Iteration 27, loss = 2.45264295\n",
      "Iteration 12, loss = 2.47176134\n",
      "Iteration 21, loss = 2.47996227\n",
      "Iteration 21, loss = 2.49437575\n",
      "Iteration 28, loss = 2.45218336\n",
      "Iteration 13, loss = 2.47062807\n",
      "Iteration 22, loss = 2.47887289\n",
      "Iteration 22, loss = 2.49482918\n",
      "Iteration 29, loss = 2.45210983\n",
      "Iteration 14, loss = 2.46965252\n",
      "Iteration 23, loss = 2.47949727\n",
      "Iteration 23, loss = 2.49428411\n",
      "Iteration 30, loss = 2.45187786\n",
      "Iteration 15, loss = 2.46879240\n",
      "Iteration 24, loss = 2.47906409\n",
      "Iteration 24, loss = 2.49378380\n",
      "Iteration 31, loss = 2.45130271\n",
      "Iteration 16, loss = 2.46827090\n",
      "Iteration 25, loss = 2.47866199\n",
      "Iteration 25, loss = 2.49402789\n",
      "Iteration 32, loss = 2.45174676\n",
      "Iteration 17, loss = 2.46808626\n",
      "Iteration 26, loss = 2.47884316\n",
      "Iteration 26, loss = 2.49366069\n",
      "Iteration 33, loss = 2.45113927\n",
      "Iteration 18, loss = 2.46720703\n",
      "Iteration 27, loss = 2.47789863\n",
      "Iteration 27, loss = 2.49347901\n",
      "Iteration 34, loss = 2.45149298\n",
      "Iteration 19, loss = 2.46729429\n",
      "Iteration 28, loss = 2.47795317\n",
      "Iteration 28, loss = 2.49361957\n",
      "Iteration 35, loss = 2.45125195\n",
      "Iteration 20, loss = 2.46673307\n",
      "Iteration 29, loss = 2.47792149\n",
      "Iteration 29, loss = 2.49333701\n",
      "Iteration 36, loss = 2.45068840\n",
      "Iteration 21, loss = 2.46626145\n",
      "Iteration 30, loss = 2.47782220\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 30, loss = 2.49340615\n",
      "Iteration 37, loss = 2.45095926\n",
      "Iteration 22, loss = 2.46565247\n",
      "Iteration 1, loss = 13.37590805\n",
      "Iteration 31, loss = 2.49285801\n",
      "Iteration 38, loss = 2.45049494\n",
      "Iteration 23, loss = 2.46541086\n",
      "Iteration 2, loss = 2.77826190\n",
      "Iteration 32, loss = 2.49312440\n",
      "Iteration 39, loss = 2.45047770\n",
      "Iteration 24, loss = 2.46506656\n",
      "Iteration 3, loss = 2.75986686\n",
      "Iteration 33, loss = 2.49290035\n",
      "Iteration 40, loss = 2.45011398\n",
      "Iteration 25, loss = 2.46495522\n",
      "Iteration 4, loss = 2.75404121\n",
      "Iteration 34, loss = 2.49264970\n",
      "Iteration 41, loss = 2.45002906\n",
      "Iteration 26, loss = 2.46496953\n",
      "Iteration 5, loss = 2.74966430\n",
      "Iteration 35, loss = 2.49244703\n",
      "Iteration 42, loss = 2.44984308\n",
      "Iteration 27, loss = 2.46447579\n",
      "Iteration 6, loss = 2.74686283\n",
      "Iteration 36, loss = 2.49221121\n",
      "Iteration 43, loss = 2.45041345\n",
      "Iteration 28, loss = 2.46433162\n",
      "Iteration 7, loss = 2.74522525\n",
      "Iteration 37, loss = 2.49318443\n",
      "Iteration 44, loss = 2.44997150\n",
      "Iteration 29, loss = 2.46438668\n",
      "Iteration 38, loss = 2.49249067\n",
      "Iteration 8, loss = 2.74417924\n",
      "Iteration 45, loss = 2.44949640\n",
      "Iteration 30, loss = 2.46461047\n",
      "Iteration 39, loss = 2.49235871\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 9, loss = 2.74360679\n",
      "Iteration 46, loss = 2.44980759\n",
      "Iteration 31, loss = 2.46396595\n",
      "Iteration 1, loss = 13.42413178\n",
      "Iteration 10, loss = 2.74283711\n",
      "Iteration 47, loss = 2.44984057\n",
      "Iteration 32, loss = 2.46445264\n",
      "Iteration 2, loss = 2.76316587\n",
      "Iteration 11, loss = 2.74276647\n",
      "Iteration 48, loss = 2.44943704\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 33, loss = 2.46380266\n",
      "Iteration 3, loss = 2.73264199\n",
      "Iteration 12, loss = 2.74217492\n",
      "Iteration 1, loss = 13.35172811\n",
      "Iteration 34, loss = 2.46392546\n",
      "Iteration 4, loss = 2.72072555\n",
      "Iteration 13, loss = 2.74203810\n",
      "Iteration 2, loss = 2.77170971\n",
      "Iteration 35, loss = 2.46345465\n",
      "Iteration 5, loss = 2.71474860\n",
      "Iteration 14, loss = 2.74218982\n",
      "Iteration 3, loss = 2.75016166\n",
      "Iteration 36, loss = 2.46340682\n",
      "Iteration 6, loss = 2.71171888\n",
      "Iteration 15, loss = 2.74169564\n",
      "Iteration 4, loss = 2.74283695\n",
      "Iteration 37, loss = 2.46342131\n",
      "Iteration 16, loss = 2.74132698\n",
      "Iteration 5, loss = 2.73875661\n",
      "Iteration 7, loss = 2.70961609\n",
      "Iteration 38, loss = 2.46362220\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 17, loss = 2.74134083\n",
      "Iteration 6, loss = 2.73640981\n",
      "Iteration 8, loss = 2.70807348\n",
      "Iteration 1, loss = 13.20366817\n",
      "Iteration 18, loss = 2.74126752\n",
      "Iteration 2, loss = 2.77678842\n",
      "Iteration 9, loss = 2.70730730\n",
      "Iteration 7, loss = 2.73467216\n",
      "Iteration 19, loss = 2.74121164\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 3, loss = 2.76085535\n",
      "Iteration 10, loss = 2.70698858\n",
      "Iteration 8, loss = 2.73392182\n",
      "Iteration 1, loss = 13.31123570\n",
      "Iteration 4, loss = 2.75532569\n",
      "Iteration 11, loss = 2.70628276\n",
      "Iteration 9, loss = 2.73326225\n",
      "Iteration 2, loss = 2.77303103\n",
      "Iteration 5, loss = 2.75103497\n",
      "Iteration 12, loss = 2.70599573\n",
      "Iteration 10, loss = 2.73258568\n",
      "Iteration 3, loss = 2.75314238\n",
      "Iteration 6, loss = 2.74857084\n",
      "Iteration 13, loss = 2.70541718\n",
      "Iteration 11, loss = 2.73226798\n",
      "Iteration 4, loss = 2.74489539\n",
      "Iteration 14, loss = 2.70518639\n",
      "Iteration 7, loss = 2.74725556\n",
      "Iteration 12, loss = 2.73161767\n",
      "Iteration 5, loss = 2.73974772\n",
      "Iteration 15, loss = 2.70525621\n",
      "Iteration 13, loss = 2.73156758\n",
      "Iteration 6, loss = 2.73720125\n",
      "Iteration 8, loss = 2.74583730\n",
      "Iteration 16, loss = 2.70508372\n",
      "Iteration 14, loss = 2.73163162\n",
      "Iteration 9, loss = 2.74520353\n",
      "Iteration 7, loss = 2.73546318\n",
      "Iteration 17, loss = 2.70457019\n",
      "Iteration 15, loss = 2.73145407\n",
      "Iteration 10, loss = 2.74473153\n",
      "Iteration 8, loss = 2.73476401\n",
      "Iteration 18, loss = 2.70477704\n",
      "Iteration 16, loss = 2.73152792\n",
      "Iteration 11, loss = 2.74427858\n",
      "Iteration 19, loss = 2.70446448\n",
      "Iteration 9, loss = 2.73348997\n",
      "Iteration 17, loss = 2.73114144\n",
      "Iteration 12, loss = 2.74400362\n",
      "Iteration 20, loss = 2.70440429\n",
      "Iteration 10, loss = 2.73291841\n",
      "Iteration 18, loss = 2.73102631\n",
      "Iteration 13, loss = 2.74388688\n",
      "Iteration 21, loss = 2.70430247\n",
      "Iteration 11, loss = 2.73270754\n",
      "Iteration 19, loss = 2.73092644\n",
      "Iteration 14, loss = 2.74388116\n",
      "Iteration 22, loss = 2.70419427\n",
      "Iteration 12, loss = 2.73263117\n",
      "Iteration 20, loss = 2.73092785\n",
      "Iteration 15, loss = 2.74365129\n",
      "Iteration 23, loss = 2.70435189\n",
      "Iteration 13, loss = 2.73234904\n",
      "Iteration 21, loss = 2.73081850\n",
      "Iteration 16, loss = 2.74334678\n",
      "Iteration 24, loss = 2.70410719\n",
      "Iteration 14, loss = 2.73227275\n",
      "Iteration 22, loss = 2.73085459\n",
      "Iteration 17, loss = 2.74336803\n",
      "Iteration 25, loss = 2.70396821\n",
      "Iteration 15, loss = 2.73213373\n",
      "Iteration 23, loss = 2.73057241\n",
      "Iteration 18, loss = 2.74339902\n",
      "Iteration 26, loss = 2.70373088\n",
      "Iteration 16, loss = 2.73180322\n",
      "Iteration 24, loss = 2.73055049\n",
      "Iteration 19, loss = 2.74310978\n",
      "Iteration 27, loss = 2.70388023\n",
      "Iteration 17, loss = 2.73182312\n",
      "Iteration 25, loss = 2.73059402\n",
      "Iteration 20, loss = 2.74300037\n",
      "Iteration 28, loss = 2.70375927\n",
      "Iteration 18, loss = 2.73155981\n",
      "Iteration 26, loss = 2.73034254\n",
      "Iteration 21, loss = 2.74299351\n",
      "Iteration 29, loss = 2.70351752\n",
      "Iteration 19, loss = 2.73140593\n",
      "Iteration 27, loss = 2.73010977\n",
      "Iteration 22, loss = 2.74281632\n",
      "Iteration 30, loss = 2.70333360\n",
      "Iteration 20, loss = 2.73148740\n",
      "Iteration 28, loss = 2.73051681\n",
      "Iteration 23, loss = 2.74253874\n",
      "Iteration 31, loss = 2.70345442\n",
      "Iteration 21, loss = 2.73143854\n",
      "Iteration 29, loss = 2.73008391\n",
      "Iteration 24, loss = 2.74278360\n",
      "Iteration 32, loss = 2.70352156\n",
      "Iteration 22, loss = 2.73124687\n",
      "Iteration 30, loss = 2.73004027\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 25, loss = 2.74272528\n",
      "Iteration 33, loss = 2.70314972\n",
      "Iteration 23, loss = 2.73117007\n",
      "Iteration 1, loss = 18.70003266\n",
      "Iteration 26, loss = 2.74262377\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 34, loss = 2.70348826\n",
      "Iteration 24, loss = 2.73097394\n",
      "Iteration 2, loss = 2.71188228\n",
      "Iteration 1, loss = 18.85036524\n",
      "Iteration 35, loss = 2.70327720\n",
      "Iteration 25, loss = 2.73081985\n",
      "Iteration 3, loss = 2.70767329\n",
      "Iteration 2, loss = 2.71235046\n",
      "Iteration 36, loss = 2.70314034\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 26, loss = 2.73087575\n",
      "Iteration 4, loss = 2.70767937\n",
      "Iteration 3, loss = 2.70774156\n",
      "Iteration 1, loss = 18.58339184\n",
      "Iteration 27, loss = 2.73100703\n",
      "Iteration 5, loss = 2.70764029\n",
      "Iteration 4, loss = 2.70764326\n",
      "Iteration 2, loss = 2.71158331\n",
      "Iteration 28, loss = 2.73071061\n",
      "Iteration 6, loss = 2.70756784\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 5, loss = 2.70761924\n",
      "Iteration 3, loss = 2.70774406\n",
      "Iteration 29, loss = 2.73070378\n",
      "Iteration 1, loss = 18.51921794\n",
      "Iteration 6, loss = 2.70761333\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 4, loss = 2.70766406\n",
      "Iteration 30, loss = 2.73086587\n",
      "Iteration 2, loss = 2.71124954\n",
      "Iteration 1, loss = 18.63246436\n",
      "Iteration 5, loss = 2.70764016\n",
      "Iteration 31, loss = 2.73052285\n",
      "Iteration 3, loss = 2.70772286\n",
      "Iteration 2, loss = 2.71156495\n",
      "Iteration 6, loss = 2.70758577\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 32, loss = 2.73070572\n",
      "Iteration 4, loss = 2.70767088\n",
      "Iteration 3, loss = 2.70768801\n",
      "Iteration 1, loss = 28.32459032\n",
      "Iteration 33, loss = 2.73047190\n",
      "Iteration 5, loss = 2.70772774\n",
      "Iteration 4, loss = 2.70763251\n",
      "Iteration 2, loss = 2.70760314\n",
      "Iteration 34, loss = 2.73061573\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 6, loss = 2.70762632\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 5, loss = 2.70760631\n",
      "Iteration 3, loss = 2.70751812\n",
      "Iteration 1, loss = 28.38070539\n",
      "Iteration 1, loss = 28.26182415\n",
      "Iteration 6, loss = 2.70755464\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 4, loss = 2.70758975\n",
      "Iteration 2, loss = 2.70762856\n",
      "Iteration 2, loss = 2.70761054\n",
      "Iteration 1, loss = 28.04894630\n",
      "Iteration 5, loss = 2.70760874\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 3, loss = 2.70758368\n",
      "Iteration 3, loss = 2.70758439\n",
      "Iteration 2, loss = 2.70757857\n",
      "Iteration 1, loss = 28.23535763\n",
      "Iteration 4, loss = 2.70759396\n",
      "Iteration 4, loss = 2.70761940\n",
      "Iteration 3, loss = 2.70756555\n",
      "Iteration 2, loss = 2.70757298\n",
      "Iteration 5, loss = 2.70759555\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 5, loss = 2.70763808\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 4, loss = 2.70760335\n",
      "Iteration 3, loss = 2.70753356\n",
      "Iteration 5, loss = 2.70774233\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 4, loss = 2.70754519\n",
      "Iteration 5, loss = 2.70756163\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 3.11582393\n",
      "Iteration 2, loss = 1.90860280\n",
      "Iteration 3, loss = 1.62041518\n",
      "Iteration 4, loss = 1.54257556\n",
      "Iteration 5, loss = 1.51342843\n",
      "Iteration 6, loss = 1.49859498\n",
      "Iteration 7, loss = 1.48720251\n",
      "Iteration 8, loss = 1.47752452\n",
      "Iteration 9, loss = 1.47016392\n",
      "Iteration 10, loss = 1.46320464\n",
      "Iteration 11, loss = 1.45781597\n",
      "Iteration 12, loss = 1.45309501\n",
      "Iteration 13, loss = 1.44959284\n",
      "Iteration 14, loss = 1.44558554\n",
      "Iteration 15, loss = 1.44189207\n",
      "Iteration 16, loss = 1.43880488\n",
      "Iteration 17, loss = 1.43591412\n",
      "Iteration 18, loss = 1.43306261\n",
      "Iteration 19, loss = 1.43239980\n",
      "Iteration 20, loss = 1.42854941\n",
      "Iteration 21, loss = 1.42601497\n",
      "Iteration 22, loss = 1.42429689\n",
      "Iteration 23, loss = 1.42332108\n",
      "Iteration 24, loss = 1.42190887\n",
      "Iteration 25, loss = 1.42057033\n",
      "Iteration 26, loss = 1.41870125\n",
      "Iteration 27, loss = 1.41769490\n",
      "Iteration 28, loss = 1.41660199\n",
      "Iteration 29, loss = 1.41607487\n",
      "Iteration 30, loss = 1.41540315\n",
      "Iteration 31, loss = 1.41405158\n",
      "Iteration 32, loss = 1.41258506\n",
      "Iteration 33, loss = 1.41170493\n",
      "Iteration 34, loss = 1.41097283\n",
      "Iteration 35, loss = 1.40938181\n",
      "Iteration 36, loss = 1.40863714\n",
      "Iteration 37, loss = 1.40797195\n",
      "Iteration 38, loss = 1.40790073\n",
      "Iteration 39, loss = 1.40786198\n",
      "Iteration 40, loss = 1.40626905\n",
      "Iteration 41, loss = 1.40522372\n",
      "Iteration 42, loss = 1.40553051\n",
      "Iteration 43, loss = 1.40427903\n",
      "Iteration 44, loss = 1.40402835\n",
      "Iteration 45, loss = 1.40345667\n",
      "Iteration 46, loss = 1.40268098\n",
      "Iteration 47, loss = 1.40201534\n",
      "Iteration 48, loss = 1.40194623\n",
      "Iteration 49, loss = 1.40096870\n",
      "Iteration 50, loss = 1.40099221\n",
      "Iteration 51, loss = 1.40064478\n",
      "Iteration 52, loss = 1.39934940\n",
      "Iteration 53, loss = 1.39875753\n",
      "Iteration 54, loss = 1.39905509\n",
      "Iteration 55, loss = 1.39885354\n",
      "Iteration 56, loss = 1.39846719\n",
      "Iteration 57, loss = 1.39749413\n",
      "Iteration 58, loss = 1.39753965\n",
      "Iteration 59, loss = 1.39786885\n",
      "Iteration 60, loss = 1.39647548\n",
      "Iteration 61, loss = 1.39594173\n",
      "Iteration 62, loss = 1.39584348\n",
      "Iteration 63, loss = 1.39512608\n",
      "Iteration 64, loss = 1.39508582\n",
      "Iteration 65, loss = 1.39428658\n",
      "Iteration 66, loss = 1.39420735\n",
      "Iteration 67, loss = 1.39407378\n",
      "Iteration 68, loss = 1.39421608\n",
      "Iteration 69, loss = 1.39344478\n",
      "Iteration 70, loss = 1.39310550\n",
      "Iteration 71, loss = 1.39269332\n",
      "Iteration 72, loss = 1.39259563\n",
      "Iteration 73, loss = 1.39225572\n",
      "Iteration 74, loss = 1.39148156\n",
      "Iteration 75, loss = 1.39162494\n",
      "Iteration 76, loss = 1.39124805\n",
      "Iteration 77, loss = 1.39174869\n",
      "Iteration 78, loss = 1.39048872\n",
      "Iteration 79, loss = 1.39013293\n",
      "Iteration 80, loss = 1.38971909\n",
      "Iteration 81, loss = 1.38931696\n",
      "Iteration 82, loss = 1.38949254\n",
      "Iteration 83, loss = 1.38959069\n",
      "Iteration 84, loss = 1.38836259\n",
      "Iteration 85, loss = 1.38888425\n",
      "Iteration 86, loss = 1.38876588\n",
      "Iteration 87, loss = 1.38841406\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=10.0, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100, 100, 100), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=42, shuffle=True,\n",
       "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=True,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "np.random.seed(45)\n",
    "param_grid = {#\"hidden_layer_sizes\":[(128,256),(128,64)],\n",
    "    \"alpha\":np.logspace(1, 3, 7),\n",
    "    #\"learning_rate_init\":np.logspace(-4,-1,3),\n",
    "    #\"momentum\": [0.6, 0.7, 0.8, 0.9]\n",
    "}\n",
    "\n",
    "clf = MLPClassifier(hidden_layer_sizes=(100,100,100), random_state =42, verbose=True)\n",
    "gs = GridSearchCV(clf, param_grid, cv=5, n_jobs=-1)\n",
    "gs.fit(ft, lb)\n",
    "\n",
    "gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['audio/b021_30_60.wav' 'audio/b021_150_180.wav' 'audio/b021_90_120.wav'\n",
      " 'audio/b021_120_150.wav' 'audio/b021_60_90.wav' 'audio/b021_180_210.wav'\n",
      " 'audio/b021_0_30.wav' 'audio/b019_180_210.wav' 'audio/b019_120_150.wav'\n",
      " 'audio/b019_90_120.wav' 'audio/b019_150_180.wav' 'audio/b019_60_90.wav'\n",
      " 'audio/b019_0_30.wav' 'audio/b019_30_60.wav' 'audio/b020_90_120.wav'\n",
      " 'audio/b020_30_60.wav' 'audio/b020_150_180.wav' 'audio/b020_60_90.wav'\n",
      " 'audio/b020_180_210.wav' 'audio/b020_0_30.wav' 'audio/b020_120_150.wav'\n",
      " 'audio/a104_0_30.wav' 'audio/a104_150_180.wav' 'audio/a104_90_120.wav'\n",
      " 'audio/a104_60_90.wav' 'audio/a104_30_60.wav' 'audio/a104_120_150.wav'\n",
      " 'audio/a140_120_150.wav' 'audio/a140_150_180.wav' 'audio/a140_90_120.wav'\n",
      " 'audio/a140_60_90.wav' 'audio/a140_30_60.wav' 'audio/a140_240_270.wav'\n",
      " 'audio/a140_210_240.wav' 'audio/a140_180_210.wav' 'audio/a140_0_30.wav'\n",
      " 'audio/a054_0_30.wav' 'audio/a054_60_90.wav' 'audio/a054_90_120.wav'\n",
      " 'audio/a054_120_150.wav' 'audio/a054_30_60.wav' 'audio/a052_150_180.wav'\n",
      " 'audio/a052_30_60.wav' 'audio/a052_120_150.wav' 'audio/a052_60_90.wav'\n",
      " 'audio/a052_90_120.wav' 'audio/a052_0_30.wav' 'audio/a053_90_120.wav'\n",
      " 'audio/a053_150_180.wav' 'audio/a053_0_30.wav' 'audio/a053_120_150.wav'\n",
      " 'audio/a053_60_90.wav' 'audio/a106_240_270.wav' 'audio/a106_150_180.wav'\n",
      " 'audio/a106_180_210.wav' 'audio/a106_60_90.wav' 'audio/a106_270_300.wav'\n",
      " 'audio/a106_90_120.wav' 'audio/a106_30_60.wav' 'audio/a106_120_150.wav'\n",
      " 'audio/b097_90_120.wav' 'audio/b097_180_210.wav' 'audio/b097_240_270.wav'\n",
      " 'audio/b097_150_180.wav' 'audio/b097_0_30.wav' 'audio/b097_120_150.wav'\n",
      " 'audio/b097_30_60.wav' 'audio/b097_210_240.wav' 'audio/a094_150_180.wav'\n",
      " 'audio/a094_60_90.wav' 'audio/a094_30_60.wav' 'audio/a094_90_120.wav'\n",
      " 'audio/a094_120_150.wav' 'audio/a062_120_150.wav' 'audio/a062_0_30.wav'\n",
      " 'audio/a062_60_90.wav' 'audio/a062_90_120.wav' 'audio/a062_150_180.wav'\n",
      " 'audio/a062_30_60.wav' 'audio/a129_180_210.wav' 'audio/a129_30_60.wav'\n",
      " 'audio/a129_150_180.wav' 'audio/a129_60_90.wav' 'audio/a129_120_150.wav'\n",
      " 'audio/a129_210_240.wav' 'audio/a129_0_30.wav' 'audio/b091_122_152.wav'\n",
      " 'audio/b091_0_30.wav' 'audio/b091_182_212.wav' 'audio/b091_30_60.wav'\n",
      " 'audio/b091_152_182.wav' 'audio/b095_60_90.wav' 'audio/b095_0_30.wav'\n",
      " 'audio/b095_120_150.wav' 'audio/b095_150_180.wav' 'audio/b095_180_210.wav'\n",
      " 'audio/b095_210_240.wav' 'audio/b095_90_120.wav' 'audio/a066_90_120.wav'\n",
      " 'audio/a066_30_60.wav' 'audio/a066_60_90.wav' 'audio/a066_0_30.wav'\n",
      " 'audio/a097_210_240.wav' 'audio/a097_180_210.wav' 'audio/a097_60_90.wav'\n",
      " 'audio/a097_90_120.wav' 'audio/a097_150_180.wav' 'audio/a097_240_270.wav'\n",
      " 'audio/a097_0_30.wav' 'audio/a097_30_60.wav' 'audio/a097_120_150.wav'\n",
      " 'audio/a039_0_30.wav' 'audio/a039_90_120.wav' 'audio/a039_120_150.wav'\n",
      " 'audio/a039_30_60.wav' 'audio/a039_60_90.wav' 'audio/a110_210_240.wav'\n",
      " 'audio/a110_60_90.wav' 'audio/a110_90_120.wav' 'audio/a110_270_300.wav'\n",
      " 'audio/a110_240_270.wav' 'audio/a110_120_150.wav' 'audio/a110_150_180.wav'\n",
      " 'audio/a110_180_210.wav' 'audio/a110_30_60.wav' 'audio/a051_30_60.wav'\n",
      " 'audio/a051_60_90.wav' 'audio/a051_90_120.wav' 'audio/a051_150_180.wav'\n",
      " 'audio/a051_120_150.wav' 'audio/a051_0_30.wav' 'audio/b084_180_210.wav'\n",
      " 'audio/b084_90_120.wav' 'audio/b084_0_30.wav' 'audio/b084_150_180.wav'\n",
      " 'audio/b084_120_150.wav' 'audio/b084_30_60.wav' 'audio/a036_150_180.wav'\n",
      " 'audio/a036_60_90.wav' 'audio/a036_30_60.wav' 'audio/a036_90_120.wav'\n",
      " 'audio/a036_120_150.wav' 'audio/a036_0_30.wav' 'audio/b044_90_120.wav'\n",
      " 'audio/b044_60_90.wav' 'audio/b044_0_30.wav' 'audio/b044_150_180.wav'\n",
      " 'audio/b044_120_150.wav' 'audio/b044_30_60.wav' 'audio/a030_60_90.wav'\n",
      " 'audio/a030_0_30.wav' 'audio/a030_90_120.wav' 'audio/a030_30_60.wav'\n",
      " 'audio/a030_120_150.wav' 'audio/a030_150_180.wav' 'audio/b037_210_240.wav'\n",
      " 'audio/b037_60_90.wav' 'audio/b037_150_180.wav' 'audio/b037_0_30.wav'\n",
      " 'audio/b037_120_150.wav' 'audio/b037_180_210.wav' 'audio/b048_30_60.wav'\n",
      " 'audio/b048_150_180.wav' 'audio/b048_180_210.wav' 'audio/b048_60_90.wav'\n",
      " 'audio/b048_0_30.wav' 'audio/b048_90_120.wav' 'audio/b041_0_30.wav'\n",
      " 'audio/b041_30_60.wav' 'audio/b041_120_150.wav' 'audio/b041_150_180.wav'\n",
      " 'audio/b041_210_240.wav' 'audio/b041_180_210.wav' 'audio/b069_210_240.wav'\n",
      " 'audio/b069_120_150.wav' 'audio/b069_240_270.wav' 'audio/b069_150_180.wav'\n",
      " 'audio/b069_0_30.wav' 'audio/b069_180_210.wav' 'audio/b068_210_240.wav'\n",
      " 'audio/b068_30_60.wav' 'audio/b068_90_120.wav' 'audio/b068_0_30.wav'\n",
      " 'audio/a089_240_270.wav' 'audio/a089_150_180.wav' 'audio/a089_120_150.wav'\n",
      " 'audio/a089_90_120.wav' 'audio/a089_60_90.wav' 'audio/a089_270_300.wav'\n",
      " 'audio/a089_0_30.wav' 'audio/a089_180_210.wav' 'audio/b054_0_30.wav'\n",
      " 'audio/b054_150_180.wav' 'audio/b054_90_120.wav' 'audio/b054_60_90.wav'\n",
      " 'audio/b054_30_60.wav' 'audio/b054_180_210.wav' 'audio/b054_210_240.wav'\n",
      " 'audio/b054_120_150.wav' 'audio/a122_0_30.wav' 'audio/a122_240_270.wav'\n",
      " 'audio/a122_150_180.wav' 'audio/a122_30_60.wav' 'audio/a122_180_210.wav'\n",
      " 'audio/a122_120_150.wav' 'audio/a122_60_90.wav' 'audio/a122_270_300.wav'\n",
      " 'audio/a122_210_240.wav' 'audio/b052_30_60.wav' 'audio/b052_0_30.wav'\n",
      " 'audio/b052_150_180.wav' 'audio/b052_180_210.wav' 'audio/b052_90_120.wav'\n",
      " 'audio/b052_120_150.wav' 'audio/a020_0_30.wav' 'audio/a020_90_120.wav'\n",
      " 'audio/a020_30_60.wav' 'audio/a020_162_192.wav' 'audio/a020_60_90.wav'\n",
      " 'audio/b016_120_150.wav' 'audio/b016_150_180.wav' 'audio/b016_30_60.wav'\n",
      " 'audio/b016_90_120.wav' 'audio/b016_60_90.wav' 'audio/b016_180_210.wav'\n",
      " 'audio/b016_0_30.wav' 'audio/b023_90_120.wav' 'audio/b023_30_60.wav'\n",
      " 'audio/b023_150_180.wav' 'audio/b023_0_30.wav' 'audio/b023_60_90.wav'\n",
      " 'audio/b023_180_210.wav' 'audio/a003_90_120.wav' 'audio/a003_210_240.wav'\n",
      " 'audio/a003_60_90.wav' 'audio/a003_180_210.wav' 'audio/a003_150_180.wav'\n",
      " 'audio/a003_120_150.wav' 'audio/a003_30_60.wav' 'audio/a003_0_30.wav'\n",
      " 'audio/a010_90_120.wav' 'audio/a010_60_90.wav' 'audio/a010_0_30.wav'\n",
      " 'audio/a010_150_180.wav' 'audio/a010_120_150.wav' 'audio/a010_180_210.wav'\n",
      " 'audio/a012_30_60.wav' 'audio/a012_150_180.wav' 'audio/a012_180_210.wav'\n",
      " 'audio/a012_60_90.wav' 'audio/a012_90_120.wav' 'audio/a012_0_30.wav'\n",
      " 'audio/a012_120_150.wav' 'audio/b062_60_90.wav' 'audio/b062_0_30.wav'\n",
      " 'audio/b062_30_60.wav' 'audio/b062_90_120.wav' 'audio/b059_195_225.wav'\n",
      " 'audio/b059_30_60.wav' 'audio/b059_90_120.wav' 'audio/b059_60_90.wav'\n",
      " 'audio/b059_165_195.wav' 'audio/b059_135_165.wav' 'audio/a144_90_120.wav'\n",
      " 'audio/a144_60_90.wav' 'audio/a144_180_210.wav' 'audio/a144_120_150.wav'\n",
      " 'audio/a144_0_30.wav' 'audio/a144_210_240.wav' 'audio/a144_30_60.wav'\n",
      " 'audio/a144_240_270.wav' 'audio/a144_270_300.wav' 'audio/a153_240_270.wav'\n",
      " 'audio/a153_270_300.wav' 'audio/a153_150_180.wav' 'audio/a153_60_90.wav'\n",
      " 'audio/a153_120_150.wav' 'audio/b080_90_120.wav' 'audio/b080_210_240.wav'\n",
      " 'audio/b080_180_210.wav' 'audio/b080_261_291.wav' 'audio/b080_60_90.wav'\n",
      " 'audio/b080_150_180.wav' 'audio/b080_120_150.wav' 'audio/a149_270_300.wav'\n",
      " 'audio/a149_150_180.wav' 'audio/a149_180_210.wav' 'audio/a149_90_120.wav'\n",
      " 'audio/a149_240_270.wav' 'audio/a149_60_90.wav']\n"
     ]
    }
   ],
   "source": [
    "data_val = pd.read_csv('audio/dev.txt', header=None, sep='\\s+')\n",
    "X_val=  data_val[0].values\n",
    "y_val = pd.factorize(data_val[1])[0]\n",
    "print X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ft_val, lb_val = parse_audio_files(X_val, y_val)\n",
    "print ft_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  0  0 ..., 14 14 14]\n"
     ]
    }
   ],
   "source": [
    "print lb_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(clf, X_test):\n",
    "    y_pred = np.empty(0)\n",
    "    for x in X_test:\n",
    "        x_mfccs = extract_feature(x)\n",
    "        y_predicts = clf.predict(x_mfccs)\n",
    "        y_pred = np.append(y_pred, mode(y_predicts).mode[0])\n",
    "    return np.array(y_pred, dtype = np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on validation test: 0.864261\n",
      "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  2  2  2  2  2  2  2  6  2  6  2  2\n",
      "  2  2  2  2  2  2  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4 11  5  5 11 11  5\n",
      "  5  5  5 11  5  5  5  5  5  5  5  5  5  5  5  6  6  6  6  6  6  6  6  6  6\n",
      "  6  6  6  6  6  6  6  6  6  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7\n",
      "  7  7  7  7  7  7  8  8  8  8  8  8  8  8  8  6 14  6  6  8  8  8  8  8  8\n",
      "  8  8  6  9  9  6  6  9 14  6  2  9 14  2  7 10  7 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11  1 11  1 11  1 12 12  8 11  1 11  4  4  2 11  2  4 12  4 12\n",
      " 12  4 12  4 13 13 13 13 13 13 13  1 13 13  1 13 13 13 13  1  1  1 14 14 14\n",
      " 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14  0  0  0  0  0  0  0  0  0 11\n",
      "  0  3  0  0  0 14  0  8  0  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  4  4  4 13  4  2\n",
      "  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  5  5  5  5  5  5  5  5  5\n",
      "  5  5  5  5  5  5  5  5  5  5  5  5  6  6  6  6  6  6  6  6  6  6  6  6  0\n",
      "  6  6  6  6  6  6  8  7  7  7  7  7  7  7  7  7  8  7  8  7  7  7  8  8  8\n",
      "  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  9  9  9  9  6  9  6\n",
      "  9  6  9  9  9  9  9  9  9  9  9  9 10  8  8 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 12 12 12 11  0 11 11  4 11 11 11 11 12 12 12 12  4 12  4  1  1  1  1 13 13\n",
      " 13 13 13 13 13 13 13 13 13 13 13 13 14 14 14 14  3 14 14 14 14 14 14 14 14\n",
      " 14 14 14 14 14 14 14]\n",
      "Score on validation test: 0.589655\n",
      "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 14 14 14 14\n",
      "  1 14  1  1  1 14  1  1  1  1  1  1 14 14 14  1  2  2  2  2  2  2  2  2  2\n",
      "  2  2  6  6  6  6  6  6  6  6 14  3 14  3 14 14 14  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3  4  4  4  4  4  4  4  2  0  4  4  4  4  4  4  4  4  4  4  2  2\n",
      "  2  5  5  5  5  5  5  5  5  5  5  0  0  0  0  0  6  6  6  6  6  6  6  6  6\n",
      "  6  2  6  6  6  6  6  6  6  6  6  6  9  7  7  7  5  7  0  7  7  7  7  7  8\n",
      " 10  8  8  8  8  0  6  0  2  0  0  8  8  8  8  8  8 11  5  8 11 11  8  6 10\n",
      "  7  9 10  9  9  6  2  6  2 11  6  6  9  2  2 11 10  7 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10 10 10 10  8 10 10 10 10 11  7 11 11 11  8  8  8  8  8  8\n",
      "  8  0  0  4  0  0  0 11 11 11 11 11 11 11 11  0 11  0 11 11 11 11  5  5  5\n",
      "  5 11  5  0  1  1  0  1  1  1  1 14  1 13 13 13 13  0 13 13 13 13 14 14 14\n",
      " 14 14 14  1 14  1  1  1 14 14 14 14 11 14 14]\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = predict(gs.best_estimator_, X_train)\n",
    "print \"Score on validation test: %f\" % np.mean(y_train_pred == y_train)\n",
    "print y_train_pred\n",
    "\n",
    "y_val_pred = predict(gs.best_estimator_, X_val)\n",
    "print \"Score on validation test: %f\" % np.mean(y_val_pred == y_val)\n",
    "print y_val_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
