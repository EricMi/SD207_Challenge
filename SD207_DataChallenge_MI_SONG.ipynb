{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge SD207 - 2017\n",
    "*<p>Author: Pengfei MI, Rui SONG</p>*\n",
    "*<p>Date: 06/06/2017</p>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Basic libraries\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sys import platform\n",
    "import os\n",
    "from time import time\n",
    "from scipy.stats import mode\n",
    "\n",
    "# Librosa related: audio feature extraction\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "# Sklearn related: data preprocessing and classifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define some usefull functions\n",
    "def load_sound_file(file_name):\n",
    "    X, sr = librosa.load(os.path.join(FILEROOT, file_name), sr=None)\n",
    "    return X\n",
    "\n",
    "def extract_feature(file_name): # Late fusion\n",
    "    X, sample_rate = librosa.load(os.path.join(FILEROOT, file_name), sr=None)\n",
    "    mfcc = librosa.feature.mfcc(y=X, sr=sample_rate, n_fft=4096, hop_length=2048, n_mfcc=n_mfcc).T\n",
    "    delta_mfcc = librosa.feature.delta(mfcc, width=5, order=1, trim=True)\n",
    "    return delta_mfcc\n",
    "\n",
    "def parse_audio_files(file_names, file_labels, test_fold):\n",
    "    features, labels, tf = np.empty((0,n_features)), np.empty(0), np.empty(0)\n",
    "    for fn, fl, f in zip(file_names, file_labels, test_fold):\n",
    "        try:\n",
    "            ff = extract_feature(fn)\n",
    "        except Exception as e:\n",
    "            print \"Error encountered while parsing file: \", fn\n",
    "            continue\n",
    "        features = np.vstack([features, ff])\n",
    "        labels = np.append(labels, fl*np.ones(ff.shape[0]))\n",
    "        tf = np.append(tf, f*np.ones(ff.shape[0]))\n",
    "    return np.array(features), np.array(labels, dtype = np.int), np.array(tf, dtype=np.int)\n",
    "\n",
    "def predict(clf, X_test):\n",
    "    y_pred = np.empty(0)\n",
    "    y_pred_sum = np.empty(0)\n",
    "    y_pred_prod = np.empty(0)\n",
    "    for x in X_test:\n",
    "        x_mfccs = extract_feature(x)\n",
    "        y_predicts = clf.predict(x_mfccs)\n",
    "        y_predict_probas = clf.predict_proba(x_mfccs)\n",
    "        y_pred = np.append(y_pred, mode(y_predicts).mode[0])\n",
    "        y_pred_sum = np.append(y_pred_sum, np.argmax(np.sum(y_predict_probas, axis=0)))\n",
    "        y_pred_prod = np.append(y_pred_prod, np.argmax(np.prod(y_predict_probas, axis=0)))\n",
    "    return np.array(y_pred, dtype=np.int), np.array(y_pred_sum, dtype=np.int), np.array(y_pred_prod, dtype=np.int)\n",
    "\n",
    "def predict_maj(clf, X_test):\n",
    "    y_pred = np.empty(0)\n",
    "    for x in X_test:\n",
    "        x_mfccs = extract_feature(x)\n",
    "        y_predicts = clf.predict(x_mfccs)\n",
    "        y_pred = np.append(y_pred, mode(y_predicts).mode[0])\n",
    "    return np.array(y_pred, dtype = np.int)\n",
    "\n",
    "def predict_sum(clf, X_test):\n",
    "    y_pred = np.empty(0)\n",
    "    for x in X_test:\n",
    "        x_mfccs = extract_feature(x)\n",
    "        y_predicts = np.sum(clf.predict_proba(x_mfccs), axis=0)\n",
    "        y_pred = np.append(y_pred, np.argmax(y_predicts))\n",
    "    return np.array(y_pred, dtype = np.int)\n",
    "\n",
    "def predict_prod(clf, X_test):\n",
    "    y_pred = np.empty(0)\n",
    "    for x in X_test:\n",
    "        x_mfccs = extract_feature(x)\n",
    "        y_predicts = np.prod(clf.predict_proba(x_mfccs), axis=0)\n",
    "        y_pred = np.append(y_pred, np.argmax(y_predicts))\n",
    "    return np.array(y_pred, dtype = np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files...\n",
      "Training set size: 872\n",
      "Test set size: 298\n",
      "Done in 0.016s.\n"
     ]
    }
   ],
   "source": [
    "# Read data and preprocessing\n",
    "print \"Loading files...\"\n",
    "t0 = time()\n",
    "\n",
    "# Define FILEROOT according to the platform\n",
    "# My personal computer\n",
    "if platform == \"darwin\":\n",
    "    FILEROOT = './'\n",
    "# The machines of Telecom\n",
    "else:\n",
    "    FILEROOT = '/tsi/plato/sons/sd207/'\n",
    "\n",
    "# Load the cross validation folds\n",
    "N_FOLDS = 3\n",
    "train_files, train_labels, test_fold = np.empty(0, dtype=str), np.empty(0), np.empty(0)\n",
    "for i in range(N_FOLDS):\n",
    "    files = pd.read_csv('fold%s.txt' % str(i), sep='\\s+', header=None)[0].values\n",
    "    labels = pd.read_csv('fold%s.txt' % str(i), sep='\\s+', header=None)[1].values\n",
    "    train_files = np.append(train_files, files)\n",
    "    train_labels = np.append(train_labels, labels)\n",
    "    test_fold = np.append(test_fold, i*np.ones_like(labels))\n",
    "\n",
    "labels = np.unique(train_labels)\n",
    "n_labels = len(labels)\n",
    "test_files = pd.read_csv('test_files.txt', header=None)[0].values\n",
    "\n",
    "print \"Training set size: %d\" % len(train_files)\n",
    "print \"Test set size: %d\" % len(test_files)\n",
    "print \"Done in %0.3fs.\" % (time()-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features...\n",
      "(136770, 40) (136770,)\n",
      "Done in 27.128s.\n"
     ]
    }
   ],
   "source": [
    "# Feature extraction\n",
    "print \"Extracting features...\"\n",
    "n_mfcc = 40\n",
    "t0 = time()\n",
    "X_train, y_train, test_fold_train = parse_audio_files(train_files, train_labels, test_fold)\n",
    "print X_train.shape, y_train.shape\n",
    "print \"Done in %0.3fs.\" % (time()-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classifier...\n",
      "Done in 56.006s.\n"
     ]
    }
   ],
   "source": [
    "# Train classifier\n",
    "print \"Training classifier...\"\n",
    "np.random.seed(42)\n",
    "t0 = time()\n",
    "clf = MLPClassifier(hidden_layer_sizes=(40), alpha=0.1)\n",
    "clf.fit(X_train, y_train)\n",
    "print \"Done in %0.3fs.\" % (time()-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on validation test (vote by majority): 0.593103\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "           beach       0.62      1.00      0.76        21\n",
      "             bus       0.12      0.05      0.07        20\n",
      " cafe/restaurant       0.61      0.58      0.59        19\n",
      "             car       0.90      0.95      0.92        19\n",
      "     city_center       0.77      0.53      0.62        19\n",
      "     forest_path       0.63      0.94      0.76        18\n",
      "   grocery_store       0.72      1.00      0.84        21\n",
      "            home       0.89      0.44      0.59        18\n",
      "         library       0.50      0.56      0.53        18\n",
      "   metro_station       0.73      0.44      0.55        18\n",
      "          office       0.96      1.00      0.98        23\n",
      "            park       0.26      0.33      0.29        18\n",
      "residential_area       0.14      0.10      0.11        21\n",
      "           train       1.00      0.05      0.10        19\n",
      "            tram       0.38      0.83      0.53        18\n",
      "\n",
      "     avg / total       0.62      0.59      0.56       290\n",
      "\n",
      "Score on validation test (vote by proba sum): 0.593103\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "           beach       0.66      1.00      0.79        21\n",
      "             bus       0.14      0.05      0.07        20\n",
      " cafe/restaurant       0.61      0.58      0.59        19\n",
      "             car       0.86      1.00      0.93        19\n",
      "     city_center       0.82      0.47      0.60        19\n",
      "     forest_path       0.61      0.94      0.74        18\n",
      "   grocery_store       0.72      1.00      0.84        21\n",
      "            home       0.89      0.44      0.59        18\n",
      "         library       0.44      0.44      0.44        18\n",
      "   metro_station       0.64      0.50      0.56        18\n",
      "          office       0.96      1.00      0.98        23\n",
      "            park       0.26      0.33      0.29        18\n",
      "residential_area       0.19      0.14      0.16        21\n",
      "           train       1.00      0.11      0.19        19\n",
      "            tram       0.38      0.78      0.51        18\n",
      "\n",
      "     avg / total       0.62      0.59      0.56       290\n",
      "\n",
      "Score on validation test (vote by proba product): 0.606897\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "           beach       0.62      0.95      0.75        21\n",
      "             bus       0.17      0.05      0.08        20\n",
      " cafe/restaurant       0.69      0.58      0.63        19\n",
      "             car       0.95      0.95      0.95        19\n",
      "     city_center       0.82      0.47      0.60        19\n",
      "     forest_path       0.71      0.94      0.81        18\n",
      "   grocery_store       0.72      1.00      0.84        21\n",
      "            home       0.82      0.50      0.62        18\n",
      "         library       0.45      0.50      0.47        18\n",
      "   metro_station       0.50      0.50      0.50        18\n",
      "          office       1.00      0.96      0.98        23\n",
      "            park       0.27      0.33      0.30        18\n",
      "residential_area       0.29      0.24      0.26        21\n",
      "           train       1.00      0.16      0.27        19\n",
      "            tram       0.40      0.89      0.55        18\n",
      "\n",
      "     avg / total       0.63      0.61      0.58       290\n",
      "\n",
      "Done in 10.655s.\n"
     ]
    }
   ],
   "source": [
    "# Predicting on validation set...\n",
    "t0 = time()\n",
    "y_val_pred, y_val_pred_sum, y_val_pred_prod = predict(clf, files_val)\n",
    "print \"Score on validation test (vote by majority): %f\" % np.mean(y_val_pred == labels_val)\n",
    "print classification_report(labels_val, y_val_pred, target_names=labels)\n",
    "\n",
    "print \"Score on validation test (vote by proba sum): %f\" % np.mean(y_val_pred_sum == labels_val)\n",
    "print classification_report(labels_val, y_val_pred_sum, target_names=labels)\n",
    "\n",
    "print \"Score on validation test (vote by proba product): %f\" % np.mean(y_val_pred_prod == labels_val)\n",
    "print classification_report(labels_val, y_val_pred_prod, target_names=labels)\n",
    "print \"Done in %0.3fs.\" % (time()-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7  8  3  7 14  5  7 14  3  7  7 11  6 14 12  5 12  8  0  8  7  6  7  0 11\n",
      " 12  2  7  2  3 14 14 10 12  8  5  3  3  0  4  7  0  0  7  6  4  1  6  3  8\n",
      "  0  6  0 12 12  7  8  6  5 11  7  4 14 11  2 14  6  7  3  4  0  6 11  7 14\n",
      "  2 14  9  1  7 12  0  4  2  2  3 14 13  1  9 12 14 10  6  1 14  7 10  5 14\n",
      "  1  1  6  6 10  0  7  7  5 14  4 12  0  2  3  0  0  9  5 10 13  3  4  9  1\n",
      " 14 14 12  4  5 14  7  1 10  2  2 11 12 12 14 12  5 12  8  3  3  5  7 14  8\n",
      "  7  3  3 13  9 13 12  0 14  6  2  4  5  9 14  1  9  5  7  7 14 13  0  0 11\n",
      " 14  8  5 12  5  5  6  4  2  5  2  4 14  5  9 14  7  4 11  9  3  9  2  7  0\n",
      " 14  7 14  3 11  0 14 14  0  4  9  6  6  7 11  2  6 14  2 14  2  7  3  2  5\n",
      " 12 13 14  2  4  9  0 12  7 12  7  8  5  4  5  7  7  3 11  9  5  4  7  0  1\n",
      "  4  2 14  6 10  5 14  5 14  8 10  7 12  8  8 12  7  0 14  4 10  3  6 14  4\n",
      " 11  2 14  8  7  9  5  3 14  2  6 10 14  4  0  9  7  0  9  7  9  5 12]\n"
     ]
    }
   ],
   "source": [
    "y_test_pred, y_test_pred_sum, y_test_pred_prod = predict(clf, files_test)\n",
    "np.savetxt('y_test_pred_delta_mfcc_mlp.txt', y_test_pred, fmt='%d')\n",
    "np.savetxt('y_test_pred_delta_mfcc_mlp_sum.txt', y_test_pred_sum, fmt='%d')\n",
    "np.savetxt('y_test_pred_delta_mfcc_mlp_prod.txt', y_test_pred_prod, fmt='%d')\n",
    "print y_test_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
