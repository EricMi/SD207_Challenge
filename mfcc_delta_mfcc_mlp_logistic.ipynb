{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge SD207 - 2017\n",
    "*<p>Author: Pengfei MI, Rui SONG</p>*\n",
    "*<p>Date: 06/06/2017</p>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy.stats import mode\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn import linear_model\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define some usefull functions\n",
    "def load_sound_file(file_path):\n",
    "    X, sr = librosa.load(file_path, sr=None)\n",
    "    return X\n",
    "\n",
    "def extract_feature(file_name): # Late fusion\n",
    "    X, sample_rate = librosa.load(file_name, sr=None)\n",
    "    #mfcc = librosa.feature.mfcc(y=librosa.effects.harmonic(X), \n",
    "    #sr=sample_rate, n_fft=4096, hop_length=2048, n_mfcc=n_mfcc).T\n",
    "    mfcc = librosa.feature.mfcc(y=X, sr=sample_rate, n_fft=4096, hop_length=4096, n_mfcc=n_mfcc).T\n",
    "    mfcc_delta = librosa.feature.delta(mfcc, width=5, order=1, trim=True)\n",
    "    return mfcc, mfcc_delta\n",
    "\n",
    "def parse_audio_files(file_names, file_labels):\n",
    "    features, features_delta, labels = np.empty((0,n_mfcc-1)), np.empty((0,n_mfcc)), np.empty(0)\n",
    "    for fn, fl in zip(file_names, file_labels):\n",
    "        try:\n",
    "            mfcc, mfcc_delta = extract_feature(fn)\n",
    "        except Exception as e:\n",
    "            print \"Error encountered while parsing file: \", fn\n",
    "            continue\n",
    "        features = np.vstack([features, mfcc])\n",
    "        features_delta = np.vstack([features_delta, mfcc_delta])\n",
    "        labels = np.append(labels, fl*np.ones(mfcc.shape[0]))\n",
    "    return np.array(features), np.array(features_delta), np.array(labels, dtype = np.int)\n",
    "\n",
    "def predict_proba(clf1, clf2, X_val):\n",
    "    pred_proba = np.empty((0,30))\n",
    "    for x in X_val:\n",
    "        x_mfcc, x_mfcc_delta = extract_feature(x)\n",
    "        y_pred_proba1 = np.sum(clf1.predict_proba(x_mfcc), axis=0).reshape(-1)\n",
    "        y_pred_proba2 = np.sum(clf2.predict_proba(x_mfcc_delta), axis=0).reshape(-1)\n",
    "        pred_proba = np.vstack([pred_proba,np.hstack([y_pred_proba1,y_pred_proba2])])\n",
    "        #print pred_proba.shape\n",
    "    return np.array(pred_proba, dtype=np.int)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "def predict(clf, X_test):\n",
    "    y_pred = np.empty(0)\n",
    "    y_pred_sum = np.empty(0)\n",
    "    y_pred_prod = np.empty(0)\n",
    "    for x in X_test:\n",
    "        x_mfccs = extract_feature(x)\n",
    "        y_predicts = clf.predict(x_mfccs)\n",
    "        y_predict_probas = clf.predict_proba(x_mfccs)\n",
    "        y_pred = np.append(y_pred, mode(y_predicts).mode[0])\n",
    "        y_pred_sum = np.append(y_pred_sum, np.argmax(np.sum(y_predict_probas, axis=0)))\n",
    "        y_pred_prod = np.append(y_pred_prod, np.argmax(np.prod(y_predict_probas, axis=0)))\n",
    "    return np.array(y_pred, dtype=np.int), np.array(y_pred_sum, dtype=np.int), np.array(y_pred_prod, dtype=np.int)\n",
    "\n",
    "def predict_maj(clf, X_test):\n",
    "    y_pred = np.empty(0)\n",
    "    for x in X_test:\n",
    "        x_mfccs = extract_feature(x)\n",
    "        y_predicts = clf.predict(x_mfccs)\n",
    "        y_pred = np.append(y_pred, mode(y_predicts).mode[0])\n",
    "    return np.array(y_pred, dtype = np.int)\n",
    "\n",
    "def predict_sum(clf, X_test):\n",
    "    y_pred = np.empty(0)\n",
    "    for x in X_test:\n",
    "        x_mfccs = extract_feature(x)\n",
    "        y_predicts = np.sum(clf.predict_proba(x_mfccs), axis=0)\n",
    "        y_pred = np.append(y_pred, np.argmax(y_predicts))\n",
    "    return np.array(y_pred, dtype = np.int)\n",
    "\n",
    "def predict_prod(clf, X_test):\n",
    "    y_pred = np.empty(0)\n",
    "    for x in X_test:\n",
    "        x_mfccs = extract_feature(x)\n",
    "        y_predicts = np.prod(clf.predict_proba(x_mfccs), axis=0)\n",
    "        y_pred = np.append(y_pred, np.argmax(y_predicts))\n",
    "    return np.array(y_pred, dtype = np.int)\n",
    "\"\"\"\n",
    "\n",
    "def plot_wave(title, raw_sound):\n",
    "    plt.close('all')\n",
    "    plt.figure(figsize=(20,6))\n",
    "    plt.title(title)\n",
    "    librosa.display.waveplot(np.array(raw_sound), sr=16000)\n",
    "    plt.show()\n",
    "    \n",
    "def plot_specgram(title,raw_sound):\n",
    "    plt.close('all')\n",
    "    plt.figure(figsize=(20,6))\n",
    "    plt.title(title)\n",
    "    plt.specgram(np.array(raw_sound), Fs=16000)\n",
    "    plt.show()\n",
    "\n",
    "def plot_log_power_specgram(title,raw_sound):\n",
    "    plt.close('all')\n",
    "    plt.figure(figsize=(20,6))\n",
    "    plt.title(title)\n",
    "    D = librosa.logamplitude(np.abs(librosa.stft(raw_sound))**2, ref_power=np.max)\n",
    "    librosa.display.specshow(D, x_axis='time' ,y_axis='log')\n",
    "    plt.specgram(np.array(f), Fs=16000)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files...\n",
      "Training set size: 582\n",
      "Validation set size: 290\n",
      "Test set size: 298\n",
      "Done in 0.013s.\n"
     ]
    }
   ],
   "source": [
    "# Read data and preprocessing\n",
    "print \"Loading files...\"\n",
    "t0 = time()\n",
    "FILEROOT = './'\n",
    "\n",
    "files_train = pd.read_csv('train.txt', sep='\\s+', header=None)[0].values\n",
    "labels = np.unique(pd.read_csv('train.txt', sep='\\s+', header=None)[1])\n",
    "n_labels = len(labels)\n",
    "labels_train = pd.factorize(pd.read_csv('train.txt', sep='\\s+', header=None)[1])[0]\n",
    "files_val = pd.read_csv('dev.txt', sep='\\s+', header=None)[0].values\n",
    "labels_val = pd.factorize(pd.read_csv('dev.txt', sep='\\s+', header=None)[1])[0]\n",
    "files_test = pd.read_csv('test_files.txt', header=None)[0].values\n",
    "\n",
    "print \"Training set size: %d\" % len(files_train)\n",
    "print \"Validation set size: %d\" % len(files_val)\n",
    "print \"Test set size: %d\" % len(files_test)\n",
    "print \"Done in %0.3fs.\" % (time()-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ny = load_sound_file(files_train[42])\\ny_harmonic, y_percussive = librosa.effects.hpss(y)\\nplot_wave(\"%s: original signal\" % labels[labels_train[42]], y)\\nplot_wave(\"%s: harmonic signal\" % labels[labels_train[42]], y_harmonic)\\nplot_wave(\"%s: percussive signal\" % labels[labels_train[42]], y_percussive)\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "y = load_sound_file(files_train[42])\n",
    "y_harmonic, y_percussive = librosa.effects.hpss(y)\n",
    "plot_wave(\"%s: original signal\" % labels[labels_train[42]], y)\n",
    "plot_wave(\"%s: harmonic signal\" % labels[labels_train[42]], y_harmonic)\n",
    "plot_wave(\"%s: percussive signal\" % labels[labels_train[42]], y_percussive)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-74a69800788c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mn_mfcc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mX_train1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_audio_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mX_train1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Done in %0.3fs.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-52bc7e040568>\u001b[0m in \u001b[0;36mparse_audio_files\u001b[0;34m(file_names, file_labels)\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Error encountered while parsing file: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmfcc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mfeatures_delta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures_delta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmfcc_delta\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfl\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmfcc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/rui/anaconda/lib/python2.7/site-packages/numpy/core/shape_base.pyc\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \"\"\"\n\u001b[0;32m--> 230\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly"
     ]
    }
   ],
   "source": [
    "# Feature extraction\n",
    "print \"Extracting features...\"\n",
    "n_mfcc = 40\n",
    "t0 = time()\n",
    "X_train1, X_train2, y_train = parse_audio_files(files_train, labels_train)\n",
    "print X_train1.shape, X_train2.shape, y_train.shape\n",
    "print \"Done in %0.3fs.\" % (time()-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Train classifier\n",
    "print \"Training classifier...\"\n",
    "np.random.seed(42)\n",
    "t0 = time()\n",
    "clf1 = MLPClassifier(hidden_layer_sizes=(40), alpha=0.01)\n",
    "clf1.fit(X_train1, y_train)\n",
    "print \"Training on MFCC done in %0.3fs.\" % (time()-t0)\n",
    "t0 = time()\n",
    "clf2 = MLPClassifier(hidden_layer_sizes=(40), alpha=1)\n",
    "clf2.fit(X_train2, y_train)\n",
    "print \"Training on MFCC delta done in %0.3fs.\" % (time()-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_proba_val = predict_proba(clf1, clf2, files_val)\n",
    "pred_proba_test = predict_proba(clf1, clf2, files_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print pred_proba_val.shape\n",
    "print labels_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print \"Score calibration...\"\n",
    "t0 = time()\n",
    "logistic = linear_model.LogisticRegression(C=0.0001)\n",
    "logistic.fit(pred_proba_val, labels_val)\n",
    "print \"Done in %0.3fs.\" % (time()-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_test_pred = logistic.predict(pred_proba_test)\n",
    "np.savetxt('y_test_pred_mfcc_delta_mfcc_mlp_logistic.txt', y_test_pred, fmt='%d')\n",
    "print y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
