{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge SD207 - 2017\n",
    "*<p>Author: Pengfei MI, Rui SONG</p>*\n",
    "*<p>Date: 06/06/2017</p>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy.stats import mode\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define some usefull functions\n",
    "def load_sound_files(file_paths):\n",
    "    raw_sounds = []\n",
    "    for fp in file_paths:\n",
    "        X, sr = librosa.load(fp, sr=None)\n",
    "        raw_sounds.append(X)\n",
    "    return raw_sounds\n",
    "\n",
    "def extract_feature(file_name): # Late fusion\n",
    "    X, sample_rate = librosa.load(file_name, sr=None)\n",
    "    melspec = librosa.feature.melspectrogram(y=X, sr=sample_rate, n_mels=n_mels, n_fft=4096, hop_length=2048, power=2.0).T\n",
    "    return melspec\n",
    "\n",
    "def parse_audio_files(file_names, file_labels):\n",
    "    features, labels = np.empty((0,n_mels)), np.empty(0)\n",
    "    for fn, fl in zip(file_names, file_labels):\n",
    "        mfccs = extract_feature(fn)\n",
    "        features = np.vstack([features, mfccs])\n",
    "        labels = np.append(labels, fl*np.ones(mfccs.shape[0]))\n",
    "    return np.array(features), np.array(labels, dtype = np.int)\n",
    "\n",
    "def predict_maj(clf, X_test):\n",
    "    y_pred = np.empty(0)\n",
    "    for x in X_test:\n",
    "        x_mfccs = extract_feature(x)\n",
    "        y_predicts = clf.predict(x_mfccs)\n",
    "        y_pred = np.append(y_pred, mode(y_predicts).mode[0])\n",
    "    return np.array(y_pred, dtype = np.int)\n",
    "\n",
    "def predict_sum(clf, X_test):\n",
    "    y_pred = np.empty(0)\n",
    "    for x in X_test:\n",
    "        x_mfccs = extract_feature(x)\n",
    "        y_predicts = np.sum(clf.predict_proba(x_mfccs), axis=0)\n",
    "        y_pred = np.append(y_pred, np.argmax(y_predicts))\n",
    "    return np.array(y_pred, dtype = np.int)\n",
    "\n",
    "def predict_prod(clf, X_test):\n",
    "    y_pred = np.empty(0)\n",
    "    for x in X_test:\n",
    "        x_mfccs = extract_feature(x)\n",
    "        y_predicts = np.prod(clf.predict_proba(x_mfccs), axis=0)\n",
    "        y_pred = np.append(y_pred, np.argmax(y_predicts))\n",
    "    return np.array(y_pred, dtype = np.int)\n",
    "\n",
    "def plot_waves(sound_names,raw_sounds):\n",
    "    i = 1\n",
    "    fig = plt.figure(figsize=(20, 5*len(sound_names)))\n",
    "    for n, f in zip(sound_names, raw_sounds):\n",
    "        plt.subplot(len(sound_names), 1, i)\n",
    "        librosa.display.waveplot(np.array(f), sr=16000)\n",
    "        plt.title(str(n))\n",
    "        i += 1\n",
    "    plt.suptitle(\"Figure 1: Waveplot\")\n",
    "    plt.show()\n",
    "    \n",
    "def plot_specgram(sound_names,raw_sounds):\n",
    "    i = 1\n",
    "    fig = plt.figure(figsize=(20, 5*len(sound_names)))\n",
    "    for n, f in zip(sound_names, raw_sounds):\n",
    "        plt.subplot(len(sound_names), 1, i)\n",
    "        plt.specgram(np.array(f), Fs=16000)\n",
    "        plt.title(str(n))\n",
    "        i += 1\n",
    "    plt.suptitle(\"Figure 2: Spectrogram\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_log_power_specgram(sound_names,raw_sounds):\n",
    "    i = 1\n",
    "    fig = plt.figure(figsize=(20, 5*len(sound_names)))\n",
    "    for n, f in zip(sound_names, raw_sounds):\n",
    "        plt.subplot(len(sound_names), 1, i)\n",
    "        D = librosa.logamplitude(np.abs(librosa.stft(f))**2, ref_power=np.max)\n",
    "        librosa.display.specshow(D,x_axis='time' ,y_axis='log')\n",
    "        plt.title(str(n))\n",
    "        i += 1\n",
    "    plt.suptitle(\"Figure 3: Log power spectrogram\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files...\n",
      "Training set size: 582\n",
      "Validation set size: 290\n",
      "Test set size: 298\n",
      "Done in 0.018s.\n"
     ]
    }
   ],
   "source": [
    "# Read data and preprocessing\n",
    "print \"Loading files...\"\n",
    "t0 = time()\n",
    "FILEROOT = './'\n",
    "\n",
    "files_train = pd.read_csv('train.txt', sep='\\s+', header=None)[0].values\n",
    "labels = np.unique(pd.read_csv('train.txt', sep='\\s+', header=None)[1])\n",
    "n_labels = len(labels)\n",
    "labels_train = pd.factorize(pd.read_csv('train.txt', sep='\\s+', header=None)[1])[0]\n",
    "files_val = pd.read_csv('dev.txt', sep='\\s+', header=None)[0].values\n",
    "labels_val = pd.factorize(pd.read_csv('dev.txt', sep='\\s+', header=None)[1])[0]\n",
    "files_test = pd.read_csv('test_files.txt', header=None)[0].values\n",
    "\n",
    "print \"Training set size: %d\" % len(files_train)\n",
    "print \"Validation set size: %d\" % len(files_val)\n",
    "print \"Test set size: %d\" % len(files_test)\n",
    "print \"Done in %0.3fs.\" % (time()-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#raw_sounds = load_sound_files(files_train[:2])\n",
    "\n",
    "#plot_waves(labels_train[:2], raw_sounds)\n",
    "#plot_specgram(labels_train[:2],raw_sounds)\n",
    "#plot_log_power_specgram(labels_train[:2],raw_sounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features...\n",
      "(136770, 64) (136770,)\n",
      "Done in 39.340s.\n"
     ]
    }
   ],
   "source": [
    "# Feature extraction\n",
    "n_mels = 64\n",
    "print \"Extracting features...\"\n",
    "t0 = time()\n",
    "X_train, y_train = parse_audio_files(files_train, labels_train)\n",
    "print X_train.shape, y_train.shape\n",
    "print \"Done in %0.3fs.\" % (time()-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classifier...\n",
      "Done in 209.221s.\n"
     ]
    }
   ],
   "source": [
    "# Train classifier\n",
    "print \"Training classifier...\"\n",
    "np.random.seed(42)\n",
    "t0 = time()\n",
    "clf = MLPClassifier(hidden_layer_sizes=(64, 128, 64), alpha=0.01)\n",
    "clf.fit(X_train, y_train)\n",
    "print \"Done in %0.3fs.\" % (time()-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on validation test (vote by majority): 0.520690\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "           beach       0.57      1.00      0.72        21\n",
      "             bus       0.70      0.70      0.70        20\n",
      " cafe/restaurant       0.00      0.00      0.00        19\n",
      "             car       0.58      0.79      0.67        19\n",
      "     city_center       0.68      1.00      0.81        19\n",
      "     forest_path       0.48      0.89      0.63        18\n",
      "   grocery_store       0.71      0.57      0.63        21\n",
      "            home       0.14      0.17      0.15        18\n",
      "         library       0.50      0.67      0.57        18\n",
      "   metro_station       0.42      0.56      0.48        18\n",
      "          office       1.00      0.26      0.41        23\n",
      "            park       0.57      0.44      0.50        18\n",
      "residential_area       0.29      0.10      0.14        21\n",
      "           train       0.00      0.00      0.00        19\n",
      "            tram       0.54      0.72      0.62        18\n",
      "\n",
      "     avg / total       0.49      0.52      0.47       290\n",
      "\n",
      "Score on validation test (vote by proba sum): 0.524138\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "           beach       0.57      1.00      0.72        21\n",
      "             bus       0.70      0.70      0.70        20\n",
      " cafe/restaurant       0.00      0.00      0.00        19\n",
      "             car       0.62      0.84      0.71        19\n",
      "     city_center       0.68      1.00      0.81        19\n",
      "     forest_path       0.47      0.89      0.62        18\n",
      "   grocery_store       0.71      0.57      0.63        21\n",
      "            home       0.13      0.17      0.15        18\n",
      "         library       0.48      0.61      0.54        18\n",
      "   metro_station       0.42      0.56      0.48        18\n",
      "          office       1.00      0.26      0.41        23\n",
      "            park       0.50      0.33      0.40        18\n",
      "residential_area       0.44      0.19      0.27        21\n",
      "           train       0.25      0.05      0.09        19\n",
      "            tram       0.57      0.72      0.63        18\n",
      "\n",
      "     avg / total       0.51      0.52      0.48       290\n",
      "\n",
      "Score on validation test (vote by proba product): 0.513793\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "           beach       0.40      0.95      0.56        21\n",
      "             bus       0.68      0.65      0.67        20\n",
      " cafe/restaurant       0.00      0.00      0.00        19\n",
      "             car       0.69      0.95      0.80        19\n",
      "     city_center       0.65      0.79      0.71        19\n",
      "     forest_path       0.59      0.89      0.71        18\n",
      "   grocery_store       0.67      0.57      0.62        21\n",
      "            home       0.14      0.22      0.17        18\n",
      "         library       0.58      0.61      0.59        18\n",
      "   metro_station       0.38      0.56      0.45        18\n",
      "          office       1.00      0.26      0.41        23\n",
      "            park       0.44      0.22      0.30        18\n",
      "residential_area       0.50      0.29      0.36        21\n",
      "           train       0.00      0.00      0.00        19\n",
      "            tram       0.61      0.78      0.68        18\n",
      "\n",
      "     avg / total       0.50      0.51      0.47       290\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_val_pred = predict_maj(clf, files_val)\n",
    "print \"Score on validation test (vote by majority): %f\" % np.mean(y_val_pred == labels_val)\n",
    "print classification_report(labels_val, y_val_pred, target_names=labels)\n",
    "\n",
    "y_val_pred = predict_sum(clf, files_val)\n",
    "print \"Score on validation test (vote by proba sum): %f\" % np.mean(y_val_pred == labels_val)\n",
    "print classification_report(labels_val, y_val_pred, target_names=labels)\n",
    "\n",
    "y_val_pred = predict_prod(clf, files_val)\n",
    "print \"Score on validation test (vote by proba product): %f\" % np.mean(y_val_pred == labels_val)\n",
    "print classification_report(labels_val, y_val_pred, target_names=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7  8  3  7  1  5  5  8  3  7  7 12  6 14 12  5  4  8  0  8  8 14  7 11 12\n",
      " 12 12  8 14  3 14  1  7 11  8  5  3  3  0  4  7  0  0  7 14 11 12  6  3  7\n",
      "  0  9 11 12  0  7  8 14  5 11  7  4  8 11 12 14 14  7  3  4  0 14 11  7  9\n",
      "  2  1  9  1  7 12  0  4  6  4  3 14 14 14  9 12  1  7  6  1  1  7  7  5  9\n",
      "  1  1  2 14  7  3  7  7  5  1  4 12 14  4  3  0  0 14  9  7  1  3  4  8  1\n",
      "  1  1 11  4  5 14  9  1  7  6 12 11 11 12 14 11  5 12  9  3  3  8  7  1  8\n",
      "  9  3  3  1  9  1 12  0 14  9  7  4  8  9 14  1  9  5  7  7  1  0  0  0 11\n",
      "  9  8  7 12  0  5  6  4  2  5  6  4 14  7  9  8  7  4 11  9  3  9 12  8  0\n",
      "  1  7 14  3 11  0  9 14 14  4  9  6  9  7 11  4  9 14 12  1 12  7  3  4  7\n",
      "  4  1  1  2  4  9 11 12  7  4  7 11  5  4  7  8  9  3 11  7  5  4  7 11  1\n",
      "  4  4 14  6  7  5 14  5 14  8  7  7 11 11  8 12  7  0 14  4  7  3 14  1  4\n",
      "  4  6 14  8  8  9  5  3  3  2 14  7 14  4  0  9 10  0  9  8  9  5 11]\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = predict_sum(clf, files_test)\n",
    "np.savetxt('y_test_pred_mfcc_mlp.txt', y_test_pred, fmt='%d')\n",
    "print y_test_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
